import streamlit as st
import os
import json
import time
import requests
import base64
import hashlib
import hmac
import urllib
from langchain_community.chat_models  import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage

# è®¯é£APIé…ç½®
lfasr_host = 'https://raasr.xfyun.cn/v2/api'
api_upload = '/upload'
api_get_result = '/getResult'
appid = "7fd8fde4"
secret_key = "ce4e08d9f1870b5a45dcedc60e99780f"


# è¯·æ±‚ç­¾åç”Ÿæˆ
def get_signa(appid, secret_key, ts):
    m2 = hashlib.md5()
    m2.update((appid + ts).encode('utf-8'))
    md5 = m2.hexdigest()
    md5 = bytes(md5, encoding='utf-8')
    signa = hmac.new(secret_key.encode('utf-8'), md5, hashlib.sha1).digest()
    signa = base64.b64encode(signa)
    signa = str(signa, 'utf-8')
    return signa


# ä¸Šä¼ æ–‡ä»¶åˆ°è®¯é£API
def upload_file_to_xunfei(upload_file_path):
    ts = str(int(time.time()))
    signa = get_signa(appid, secret_key, ts)

    file_len = os.path.getsize(upload_file_path)
    file_name = os.path.basename(upload_file_path)

    param_dict = {
        'appId': appid,
        'signa': signa,
        'ts': ts,
        'fileSize': file_len,
        'fileName': file_name,
        'duration': "200",
        'roleNum': 2,
        'roleType': 1
    }

    data = open(upload_file_path, 'rb').read(file_len)

    response = requests.post(url=lfasr_host + api_upload + "?" + urllib.parse.urlencode(param_dict),
                             headers={"Content-type": "application/json"}, data=data)
    result = json.loads(response.text)
    return result


# è·å–è½¬å†™ç»“æœ
def get_transcription_result(orderId):
    ts = str(int(time.time()))
    signa = get_signa(appid, secret_key, ts)

    param_dict = {
        'appId': appid,
        'signa': signa,
        'ts': ts,
        'orderId': orderId,
        'resultType': "transfer,predict"
    }

    status = 3
    while status == 3:
        response = requests.post(url=lfasr_host + api_get_result + "?" + urllib.parse.urlencode(param_dict),
                                 headers={"Content-type": "application/json"})
        result = json.loads(response.text)
        status = result['content']['orderInfo']['status']
        if status == 4:
            break
        time.sleep(5)
    return result


# è§„èŒƒåŒ–JSONæ–‡ä»¶ä¸ºå¯è¯»æ–‡æœ¬
def merge_result_for_one_vad(result_vad):
    content = []
    for rt_dic in result_vad['st']['rt']:
        spk_str = 'spk' + str(3 - int(result_vad['st']['rl'])) + '##'
        for st_dic in rt_dic['ws']:
            for cw_dic in st_dic['cw']:
                for w in cw_dic['w']:
                    spk_str += w
        spk_str += '\n'
        content.append(spk_str)
    return content


def content_to_file(content, output_file_path):
    with open(output_file_path, 'w', encoding='utf-8') as f:
        for lines in content:
            f.write(lines)


def analyze_conversation(conversation_text: str):
    """
    åˆ†æé€šè¯è®°å½•å¹¶æä¾›æ”¹è¿›å»ºè®®
    """
    # é¦–å…ˆæ ¼å¼åŒ–å¯¹è¯æ–‡æœ¬
    formatted_text = format_conversation(conversation_text)
    
    # é…ç½®OpenAI API
    llm = ChatOpenAI(
        openai_api_key="sk-gXeRXhgYsLFziprS93D5F6D31eE249D59235739b37Bd20B1",
        openai_api_base="https://openai.weavex.tech/v1",
        model_name="deepseek-r1",
        temperature=0.7
    )
    
    # ä¼˜åŒ–åçš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é”€å”®é€šè¯åˆ†æä¸“å®¶ã€‚è¿™æ˜¯ä¸€æ®µé”€å”®äººå‘˜ä¸å®¢æˆ·çš„å¯¹è¯è®°å½•ï¼Œè¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œæ·±å…¥åˆ†æï¼š

    1. æ•´ä½“è¯„åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰ï¼š
       - å¼€åœºç™½è¡¨ç°ï¼ˆ20åˆ†ï¼‰
       - éœ€æ±‚æŒ–æ˜ï¼ˆ20åˆ†ï¼‰
       - äº§å“ä»‹ç»ï¼ˆ20åˆ†ï¼‰
       - å¼‚è®®å¤„ç†ï¼ˆ20åˆ†ï¼‰
       - æˆäº¤æŠ€å·§ï¼ˆ20åˆ†ï¼‰

    2. è¯¦ç»†åˆ†æï¼š
       a) å¯¹è¯èŠ‚å¥ä¸äº’åŠ¨
          - é”€å”®èŠ‚å¥æ§åˆ¶
          - å€¾å¬ä¸å›åº”è´¨é‡
          - è¯è¯­æƒæŠŠæ§
       
       b) é”€å”®æŠ€å·§åº”ç”¨
          - SPINæŠ€å·§è¿ç”¨
          - ä»·å€¼å±•ç¤ºèƒ½åŠ›
          - ä¿ƒæˆäº¤æŠ€å·§
       
       c) å®¢æˆ·æ„å‘è¯†åˆ«
          - å®¢æˆ·å…´è¶£ç‚¹
          - è´­ä¹°æ„æ„¿å¼ºåº¦
          - å†³ç­–å½±å“å› ç´ 

    3. å…·ä½“æ”¹è¿›å»ºè®®ï¼š
       - è‡³å°‘3ä¸ªå¯ç«‹å³æ‰§è¡Œçš„æ”¹è¿›ç‚¹
       - å»ºè®®çš„è¯æœ¯ç¤ºä¾‹
       - åç»­è·Ÿè¿›å»ºè®®

    è¯·ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œå¹¶çªå‡ºå…³é”®å‘ç°ã€‚
    """
    
    # åˆ›å»ºæç¤ºæ¨¡æ¿
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ä»¥ä¸‹æ˜¯éœ€è¦åˆ†æçš„é€šè¯è®°å½•ï¼š\n\n{formatted_text}")
    ])
    
    try:
        response = llm(prompt.format_messages())
        return {
            "status": "success",
            "analysis": response.content,
            "formatted_text": formatted_text  # åŒæ—¶è¿”å›æ ¼å¼åŒ–åçš„æ–‡æœ¬
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        }


def format_conversation(raw_text: str) -> str:
    """
    å°†åŸå§‹çš„spkæ ‡è®°æ–‡æœ¬è½¬æ¢ä¸ºæ›´è§„èŒƒçš„å¯¹è¯æ ¼å¼
    
    Args:
        raw_text (str): åŸå§‹çš„å¸¦spkæ ‡è®°çš„æ–‡æœ¬
    
    Returns:
        str: æ ¼å¼åŒ–åçš„å¯¹è¯æ–‡æœ¬
    """
    lines = raw_text.strip().split('\n')
    formatted_lines = []
    current_speaker = None
    current_content = []
    
    for line in lines:
        if not line.strip():
            continue
            
        if '##' not in line:
            continue
            
        speaker, content = line.split('##')
        content = content.strip()
        
        # è·³è¿‡ç©ºå†…å®¹
        if not content:
            continue
            
        # å¦‚æœæ˜¯æ•°å­—ç¼–å·å¼€å¤´ï¼Œè·³è¿‡
        if content.strip().replace('ã€', '').isdigit():
            continue
            
        # è½¬æ¢speakeræ ‡è®°ä¸ºæ›´å‹å¥½çš„å½¢å¼
        speaker = 'å®¢æˆ·' if speaker == 'spk2' else 'é”€å”®'
        
        if speaker == current_speaker:
            current_content.append(content)
        else:
            if current_speaker and current_content:
                formatted_lines.append(f"{current_speaker}ï¼š{''.join(current_content)}")
            current_speaker = speaker
            current_content = [content]
    
    # å¤„ç†æœ€åä¸€ç»„å¯¹è¯
    if current_speaker and current_content:
        formatted_lines.append(f"{current_speaker}ï¼š{''.join(current_content)}")
    
    return '\n\n'.join(formatted_lines)


# Streamlitç•Œé¢
st.set_page_config(
    page_title="åˆ†æé€šè¯è®°å½•DemoğŸ“",
    page_icon="ğŸ“"
)

st.title("åˆ†æé€šè¯è®°å½•ï¼ˆDemoï¼‰ğŸ“")

uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ é€šè¯å½•éŸ³æ–‡ä»¶",
    type=['wav', 'mp3', 'm4a', 'ogg'],
    accept_multiple_files=True
)

if uploaded_files:
    st.write("å·²ä¸Šä¼ çš„æ–‡ä»¶:")
    for file in uploaded_files:
        st.write(f"- {file.name}")

    if st.button("å¼€å§‹åˆ†æ"):
        st.info("æ–‡ä»¶åˆ†æä¸­...")

        for uploaded_file in uploaded_files:
            with open(f"./temp_{uploaded_file.name}", "wb") as f:
                f.write(uploaded_file.getbuffer())

            result = upload_file_to_xunfei(f"./temp_{uploaded_file.name}")
            if 'content' in result and 'orderId' in result['content']:
                orderId = result['content']['orderId']
                transcription_result = get_transcription_result(orderId)

                # å¤„ç†è½¬å†™ç»“æœ
                if 'content' in transcription_result:
                    js_xunfei_result = json.loads(transcription_result['content']['orderResult'])
                    content = []
                    for result_one_vad_str in js_xunfei_result['lattice']:
                        js_result_one_vad = json.loads(result_one_vad_str['json_1best'])
                        content.extend(merge_result_for_one_vad(js_result_one_vad))

                    # è¾“å‡ºåˆ°æ–‡ä»¶
                    output_file_path = f"{uploaded_file.name}_output.txt"
                    content_to_file(content, output_file_path)
                    
                    # è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œåˆ†æ
                    with open(output_file_path, 'r', encoding='utf-8') as f:
                        conversation_text = f.read()
                    
                    # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æ
                    analysis_result = analyze_conversation(conversation_text)
                    
                    if analysis_result["status"] == "success":
                        st.success(f"æ–‡ä»¶è½¬å†™å’Œåˆ†æå·²å®Œæˆï¼")
                        
                        # ä½¿ç”¨tabsæ¥ç»„ç»‡å†…å®¹
                        tab1, tab2 = st.tabs(["ğŸ“ å¯¹è¯è®°å½•", "ğŸ“Š åˆ†æç»“æœ"])
                        
                        with tab1:
                            st.markdown("### é€šè¯è®°å½•")
                            st.markdown(analysis_result["formatted_text"])
                        
                        with tab2:
                            st.markdown("### ğŸ” é€šè¯åˆ†æç»“æœ")
                            st.markdown(analysis_result["analysis"])
                        
                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†ææŠ¥å‘Š",
                            data=f"é€šè¯è®°å½•ï¼š\n\n{analysis_result['formatted_text']}\n\nåˆ†æç»“æœï¼š\n\n{analysis_result['analysis']}",
                            file_name=f"{uploaded_file.name}_analysis_report.txt",
                            mime="text/plain"
                        )
                    else:
                        st.error(f"åˆ†æè¿‡ç¨‹å‡ºç°é”™è¯¯ï¼š{analysis_result['message']}")
                        st.success(f"ä»…å®Œæˆæ–‡ä»¶è½¬å†™ï¼Œç»“æœå·²ä¿å­˜ä¸º: {output_file_path}")
                        
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    os.remove(f"./temp_{uploaded_file.name}")
                else:
                    st.error("æœªèƒ½æˆåŠŸè·å–è½¬å†™ç»“æœï¼")
            else:
                st.error("ä¸Šä¼ æ–‡ä»¶å¤±è´¥ï¼Œæ— æ³•è·å–è®¢å•IDï¼")
