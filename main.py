import streamlit as st
import os
import json
import time
import base64
import hashlib
import hmac
import urllib
import asyncio
import aiohttp
import logging
from typing import List, Dict
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage
# é…ç½®æ—¥å¿—è¾“å‡º
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(levelname)s: %(message)s')

# è®¯é£APIé…ç½®
lfasr_host = 'https://raasr.xfyun.cn/v2/api'
api_upload = '/upload'
api_get_result = '/getResult'
appid = "7fd8fde4"
secret_key = "ce4e08d9f1870b5a45dcedc60e99780f"


# è¯·æ±‚ç­¾åç”Ÿæˆ
def get_signa(appid, secret_key, ts):
    m2 = hashlib.md5()
    m2.update((appid + ts).encode('utf-8'))
    md5 = m2.hexdigest()
    md5 = bytes(md5, encoding='utf-8')
    signa = hmac.new(secret_key.encode('utf-8'), md5, hashlib.sha1).digest()
    signa = base64.b64encode(signa)
    signa = str(signa, 'utf-8')
    return signa


async def upload_file_async(session: aiohttp.ClientSession, file_path: str) -> Dict:
    """å¼‚æ­¥ä¸Šä¼ å•ä¸ªæ–‡ä»¶"""
    ts = str(int(time.time()))
    signa = get_signa(appid, secret_key, ts)
    file_len = os.path.getsize(file_path)
    file_name = os.path.basename(file_path)
    param_dict = {
        'appId': appid,
        'signa': signa,
        'ts': ts,
        'fileSize': file_len,
        'fileName': file_name,
        'duration': "200",
        'roleNum': 2,
        'roleType': 1
    }
    url = lfasr_host + api_upload + "?" + urllib.parse.urlencode(param_dict)
    with open(file_path, 'rb') as f:
        data = f.read()
    async with session.post(url, headers={"Content-type": "application/json"}, data=data) as response:
        result = await response.json()
        logging.debug(f"ä¸Šä¼ æ–‡ä»¶ {file_name} è¿”å›ç»“æœï¼š{result}")
        return {"file_path": file_path, "result": result}


async def upload_files_async(file_paths: List[str]) -> List[Dict]:
    """å¹¶å‘ä¸Šä¼ å¤šä¸ªæ–‡ä»¶"""
    async with aiohttp.ClientSession() as session:
        tasks = [upload_file_async(session, file_path) for file_path in file_paths]
        return await asyncio.gather(*tasks)


async def get_transcription_result_async(orderId: str) -> Dict:
    """
    å¼‚æ­¥è·å–è½¬å†™ç»“æœ
    """
    ts = str(int(time.time()))
    signa = get_signa(appid, secret_key, ts)
    param_dict = {
        'appId': appid,
        'signa': signa,
        'ts': ts,
        'orderId': orderId,
        'resultType': "transfer,predict"
    }
    url = lfasr_host + api_get_result + "?" + urllib.parse.urlencode(param_dict)
    status = 3
    async with aiohttp.ClientSession() as session:
        while status == 3:
            async with session.post(url, headers={"Content-type": "application/json"}) as response:
                result = await response.json()
            status = result['content']['orderInfo']['status']
            logging.debug(f"è½¬å†™APIè°ƒç”¨è¿”å›çŠ¶æ€: {status} (orderId: {orderId})")
            if status == 4:
                break
            await asyncio.sleep(5)
    return result


def merge_result_for_one_vad(result_vad):
    """è§„èŒƒåŒ–JSONæ–‡ä»¶ä¸ºå¯è¯»æ–‡æœ¬"""
    content = []
    for rt_dic in result_vad['st']['rt']:
        spk_str = 'spk' + str(3 - int(result_vad['st']['rl'])) + '##'
        for st_dic in rt_dic['ws']:
            for cw_dic in st_dic['cw']:
                for w in cw_dic['w']:
                    spk_str += w
        spk_str += '\n'
        content.append(spk_str)
    return content


def identify_roles(raw_text: str) -> dict:
    """
    ä½¿ç”¨LLMè¯†åˆ«å¯¹è¯ä¸­çš„è§’è‰²
    """
    lines = raw_text.strip().split('\n')
    sample_dialogue = '\n'.join(lines[:10])
    llm = ChatOpenAI(
        openai_api_key="sk-gXeRXhgYsLFziprS93D5F6D31eE249D59235739b37Bd20B1",
        openai_api_base="https://openai.weavex.tech/v1",
        model_name="gpt-4o",
        temperature=0.2
    )
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¯¹è¯åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œè¯†åˆ«å‡ºspk1å’Œspk2å„è‡ªçš„è§’è‰²ï¼ˆé”€å”®è¿˜æ˜¯å®¢æˆ·ï¼‰ã€‚

    åˆ¤æ–­ä¾æ®ï¼š
    1. è¯´è¯æ–¹å¼å’Œè¯­æ°”ï¼ˆé”€å”®é€šå¸¸æ›´ä¸»åŠ¨ã€æ›´æ­£å¼ï¼‰
    2. æé—®æ–¹å¼ï¼ˆé”€å”®å€¾å‘äºå¼•å¯¼æ€§æé—®ï¼‰
    3. ä¸“ä¸šæœ¯è¯­çš„ä½¿ç”¨ï¼ˆé”€å”®æ›´å¯èƒ½ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼‰
    4. ä¿¡æ¯è·å–æ–¹å‘ï¼ˆé”€å”®å€¾å‘äºè·å–å®¢æˆ·éœ€æ±‚ä¿¡æ¯ï¼‰

    è¯·åªè¿”å›å¦‚ä¸‹æ ¼å¼çš„JSONï¼š
    {
        "spk1": "é”€å”®/å®¢æˆ·",
        "spk2": "é”€å”®/å®¢æˆ·",
        "confidence": "high/medium/low"
    }
    """
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"å¯¹è¯å†…å®¹ï¼š\n\n{sample_dialogue}")
    ])
    try:
        response = llm(prompt.format_messages())
        roles = json.loads(response.content)
        return roles
    except Exception as e:
        return {
            "spk1": "æœªçŸ¥è§’è‰²1",
            "spk2": "æœªçŸ¥è§’è‰²2",
            "confidence": "low"
        }


def format_conversation(raw_text: str) -> tuple:
    """
    å°†åŸå§‹çš„spkæ ‡è®°æ–‡æœ¬è½¬æ¢ä¸ºæ›´è§„èŒƒçš„å¯¹è¯æ ¼å¼
    """
    roles = identify_roles(raw_text)
    lines = raw_text.strip().split('\n')
    formatted_lines = []
    current_speaker = None
    current_content = []
    for line in lines:
        if not line.strip() or '##' not in line:
            continue
        speaker, content = line.split('##')
        content = content.strip()
        if not content or content.strip().replace('ã€', '').isdigit():
            continue
        speaker_role = roles.get(speaker, f"æœªçŸ¥è§’è‰²{speaker[-1]}")
        if speaker == current_speaker:
            current_content.append(content)
        else:
            if current_speaker and current_content:
                formatted_lines.append(
                    f"{roles.get(current_speaker, f'æœªçŸ¥è§’è‰²{current_speaker[-1]}')}ï¼š{''.join(current_content)}")
            current_speaker = speaker
            current_content = [content]
    if current_speaker and current_content:
        formatted_lines.append(
            f"{roles.get(current_speaker, f'æœªçŸ¥è§’è‰²{current_speaker[-1]}')}ï¼š{''.join(current_content)}")
    formatted_text = '\n\n'.join(formatted_lines)
    return formatted_text, roles


def analyze_conversation(conversation_text: str):
    """
    åˆ†æé€šè¯è®°å½•å¹¶æä¾›æ”¹è¿›å»ºè®®
    """
    formatted_text, roles = format_conversation(conversation_text)
    confidence_warning = ""
    if roles.get("confidence", "low") == "low":
        confidence_warning = "\n\n æ³¨æ„ï¼šç³»ç»Ÿå¯¹è¯´è¯è€…è§’è‰²çš„è¯†åˆ«å¯ä¿¡åº¦è¾ƒä½ï¼Œè¯·äººå·¥æ ¸å®ã€‚"
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é”€å”®é€šè¯åˆ†æä¸“å®¶ã€‚è¿™æ˜¯ä¸€æ®µå¯¹è¯è®°å½•ï¼Œå…¶ä¸­ï¼š
    - {roles['spk1']} çš„å‘è¨€ä»¥"{roles['spk1']}ï¼š"å¼€å¤´
    - {roles['spk2']} çš„å‘è¨€ä»¥"{roles['spk2']}ï¼š"å¼€å¤´

    è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œæ·±å…¥åˆ†æï¼š
    1. æ•´ä½“è¯„åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰ï¼š
       - å¼€åœºç™½è¡¨ç°ï¼ˆ20åˆ†ï¼‰
       - éœ€æ±‚æŒ–æ˜ï¼ˆ20åˆ†ï¼‰
       - äº§å“ä»‹ç»ï¼ˆ20åˆ†ï¼‰
       - å¼‚è®®å¤„ç†ï¼ˆ20åˆ†ï¼‰
       - æˆäº¤æŠ€å·§ï¼ˆ20åˆ†ï¼‰

    2. è¯¦ç»†åˆ†æï¼š
       a) å¯¹è¯èŠ‚å¥ä¸äº’åŠ¨
          - é”€å”®èŠ‚å¥æ§åˆ¶
          - å€¾å¬ä¸å›åº”è´¨é‡
          - è¯è¯­æƒæŠŠæ§

       b) é”€å”®æŠ€å·§åº”ç”¨
          - SPINæŠ€å·§è¿ç”¨
          - ä»·å€¼å±•ç¤ºèƒ½åŠ›
          - ä¿ƒæˆäº¤æŠ€å·§

       c) å®¢æˆ·æ„å‘è¯†åˆ«
          - å®¢æˆ·å…´è¶£ç‚¹
          - è´­ä¹°æ„æ„¿å¼ºåº¦
          - å†³ç­–å½±å“å› ç´ 

    3. å…·ä½“æ”¹è¿›å»ºè®®ï¼š
       - è‡³å°‘3ä¸ªå¯ç«‹å³æ‰§è¡Œçš„æ”¹è¿›ç‚¹
       - å»ºè®®çš„è¯æœ¯ç¤ºä¾‹
       - åç»­è·Ÿè¿›å»ºè®®

    è¯·ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œå¹¶çªå‡ºå…³é”®å‘ç°ã€‚
    """
    llm = ChatOpenAI(
        openai_api_key="sk-gXeRXhgYsLFziprS93D5F6D31eE249D59235739b37Bd20B1",
        openai_api_base="https://openai.weavex.tech/v1",
        model_name="deepseek-r1",
        temperature=0.7
    )
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ä»¥ä¸‹æ˜¯éœ€è¦åˆ†æçš„é€šè¯è®°å½•ï¼š\n\n{formatted_text}")
    ])
    try:
        response = llm(prompt.format_messages())
        return {
            "status": "success",
            "analysis": response.content,
            "formatted_text": formatted_text,
            "roles": roles
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        }


async def process_file(upload_result: Dict) -> Dict:
    """
    å¼‚æ­¥å¤„ç†å•ä¸ªæ–‡ä»¶ï¼šè°ƒç”¨è½¬å†™APIã€è§£æç»“æœã€ä¿å­˜è½¬å†™æ–‡æœ¬å¹¶è°ƒç”¨LLMè¿›è¡Œåˆ†æ
    """
    file_path = upload_result["file_path"]
    logging.debug(f"å¼€å§‹å¤„ç†æ–‡ä»¶ {file_path}")
    result = upload_result["result"]
    if 'content' in result and 'orderId' in result['content']:
        orderId = result['content']['orderId']
        logging.debug(f"è°ƒç”¨è½¬å†™ API å‰ï¼Œæ–‡ä»¶ {file_path}ï¼ŒorderId: {orderId}")
        transcription_result = await get_transcription_result_async(orderId)
        logging.debug(f"è½¬å†™ API è¿”å›ï¼Œæ–‡ä»¶ {file_path}")
        if 'content' in transcription_result:
            try:
                js_xunfei_result = json.loads(transcription_result['content']['orderResult'])
            except Exception as e:
                return {"file_path": file_path, "status": "error", "message": f"è§£æè½¬å†™ç»“æœå¤±è´¥: {e}"}
            content = []
            for result_one_vad_str in js_xunfei_result['lattice']:
                try:
                    js_result_one_vad = json.loads(result_one_vad_str['json_1best'])
                    content.extend(merge_result_for_one_vad(js_result_one_vad))
                except Exception as e:
                    logging.error(f"è§£æå•ä¸ªvadç»“æœé”™è¯¯: {e}")
            file_name = os.path.basename(file_path)
            output_file_path = f"{file_name}_output.txt"
            with open(output_file_path, 'w', encoding='utf-8') as f:
                for line in content:
                    f.write(line)
            with open(output_file_path, 'r', encoding='utf-8') as f:
                conversation_text = f.read()
            logging.debug(f"å¼€å§‹è°ƒç”¨LLMåˆ†æï¼Œæ–‡ä»¶ {file_path}")
            analysis_result = await asyncio.to_thread(analyze_conversation, conversation_text)
            logging.debug(f"LLMåˆ†æå®Œæˆï¼Œæ–‡ä»¶ {file_path}")
            return {
                "file_path": file_path,
                "status": "success",
                "analysis_result": analysis_result,
                "output_file_path": output_file_path
            }
        else:
            return {"file_path": file_path, "status": "error", "message": "è½¬å†™ç»“æœæ ¼å¼é”™è¯¯"}
    else:
        return {"file_path": file_path, "status": "error", "message": "ä¸Šä¼ å¤±è´¥æˆ–è¿”å›æ ¼å¼é”™è¯¯"}


async def process_all_files(temp_files: List[str], progress_placeholder) -> List[Dict]:
    """
    å¼‚æ­¥å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼šå…ˆå¹¶å‘ä¸Šä¼ ï¼Œå†å¹¶å‘å¤„ç†è½¬å†™å’Œåˆ†æï¼Œæ¯å®Œæˆä¸€ä¸ªæ–‡ä»¶æ›´æ–°è¿›åº¦
    """
    progress_bar = progress_placeholder.progress(0)
    status_text = progress_placeholder.empty()
    phase_text = progress_placeholder.empty()
    
    # ä¸Šä¼ æ–‡ä»¶é˜¶æ®µ
    phase_text.markdown("**ğŸ“¤ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...**")
    logging.debug("å¼€å§‹å¹¶å‘ä¸Šä¼ æ–‡ä»¶")
    upload_results = await upload_files_async(temp_files)
    logging.debug("å®Œæˆæ–‡ä»¶ä¸Šä¼ ")
    
    # å¤„ç†æ–‡ä»¶é˜¶æ®µ
    phase_text.markdown("**ğŸ”„ æ­£åœ¨è½¬å†™å¹¶åˆ†ææ–‡ä»¶...**")
    tasks = [process_file(upload_result) for upload_result in upload_results]
    results = []
    total = len(tasks)
    count = 0
    
    for task in asyncio.as_completed(tasks):
        result = await task
        count += 1
        progress_bar.progress(count / total)
        status_text.markdown(f"â³ å·²å®Œæˆ {count}/{total} ä¸ªæ–‡ä»¶")
        results.append(result)
    
    phase_text.markdown("**âœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼**")
    return results


def analyze_summary(all_analysis_results: List[Dict]) -> str:
    """
    å¯¹æ‰€æœ‰å¯¹è¯çš„åˆ†æç»“æœè¿›è¡Œæ±‡æ€»åˆ†æ
    """
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é”€å”®åŸ¹è®­ä¸“å®¶ã€‚è¯·å¯¹å¤šä¸ªé”€å”®å¯¹è¯çš„åˆ†æç»“æœè¿›è¡Œæ±‡æ€»åˆ†æã€‚
    
    è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œæ€»ç»“ï¼š
    
    1. æ•´ä½“è¡¨ç°è¯„ä¼°
       - å›¢é˜Ÿæ•´ä½“å¾—åˆ†æƒ…å†µ
       - å…±åŒçš„ä¼˜åŠ¿é¢†åŸŸ
       - æ™®éå­˜åœ¨çš„é—®é¢˜
    
    2. å…¸å‹æ¡ˆä¾‹åˆ†æ
       - æœ€ä½³å®è·µæ¡ˆä¾‹åŠå…¶å¯å€Ÿé‰´ä¹‹å¤„
       - å…¸å‹é—®é¢˜æ¡ˆä¾‹åŠæ”¹è¿›å»ºè®®
    
    3. ç³»ç»Ÿæ€§æ”¹è¿›å»ºè®®
       - å›¢é˜Ÿå±‚é¢çš„åŸ¹è®­é‡ç‚¹
       - å…·ä½“çš„æ”¹è¿›è¡ŒåŠ¨è®¡åˆ’
       - è¯æœ¯å’ŒæŠ€å·§çš„æ ‡å‡†åŒ–å»ºè®®
    
    4. æ•°æ®åˆ†æ
       - å„ç»´åº¦å¾—åˆ†çš„ç»Ÿè®¡åˆ†æ
       - æˆåŠŸç‡å’Œå…³é”®å½±å“å› ç´ 
       - ç»©æ•ˆæ”¹è¿›çš„é‡åŒ–ç›®æ ‡
    
    è¯·ç”¨æ¸…æ™°çš„ç»“æ„å’Œä¸“ä¸šçš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œçªå‡ºå…³é”®å‘ç°å’Œå¯æ‰§è¡Œçš„å»ºè®®ã€‚
    """
    
    llm = ChatOpenAI(
        openai_api_key="sk-gXeRXhgYsLFziprS93D5F6D31eE249D59235739b37Bd20B1",
        openai_api_base="https://openai.weavex.tech/v1",
        model_name="gpt-4o",
        temperature=0.7
    )
    
    # å‡†å¤‡æ‰€æœ‰åˆ†æç»“æœçš„æ–‡æœ¬
    all_analyses = []
    for idx, result in enumerate(all_analysis_results, 1):
        if result["status"] == "success" and result["analysis_result"].get("status") == "success":
            all_analyses.append(f"å¯¹è¯ {idx} çš„åˆ†æç»“æœï¼š\n{result['analysis_result']['analysis']}")
    
    combined_analyses = "\n\n".join(all_analyses)
    
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ä»¥ä¸‹æ˜¯{len(all_analyses)}ä¸ªé”€å”®å¯¹è¯çš„åˆ†æç»“æœï¼Œè¯·è¿›è¡Œæ±‡æ€»åˆ†æï¼š\n\n{combined_analyses}")
    ])
    
    try:
        response = llm(prompt.format_messages())
        return response.content
    except Exception as e:
        return f"æ±‡æ€»åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"


# Streamlitç•Œé¢
st.set_page_config(page_title="åˆ†æé€šè¯è®°å½•Demo", page_icon="ğŸ“")
st.title("åˆ†æé€šè¯è®°å½•ï¼ˆDemoï¼‰ğŸ“")

uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ é€šè¯å½•éŸ³æ–‡ä»¶",
    type=['wav', 'mp3', 'm4a', 'ogg'],
    accept_multiple_files=True
)

if uploaded_files:
    st.write("å·²ä¸Šä¼ çš„æ–‡ä»¶:")
    for file in uploaded_files:
        st.write(f"- {file.name}")

    if st.button("å¼€å§‹åˆ†æ"):
        progress_placeholder = st.container()

        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶å¤¹
        temp_files = []
        for uploaded_file in uploaded_files:
            temp_path = f"./temp_{uploaded_file.name}"
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            temp_files.append(temp_path)

        try:
            results = asyncio.run(process_all_files(temp_files, progress_placeholder))
            
            # åˆ›å»ºä¸‰ä¸ªä¸»è¦æ ‡ç­¾é¡µ
            tab1, tab2, tab3 = st.tabs(["ğŸ“ æ‰€æœ‰å¯¹è¯è®°å½•", "ğŸ“Š æ‰€æœ‰åˆ†æç»“æœ", "ğŸ“ˆ æ±‡æ€»åˆ†æ"])
            
            with tab1:
                for idx, res in enumerate(results, 1):
                    if res["status"] == "success":
                        analysis_result = res["analysis_result"]
                        if analysis_result.get("status") == "success":
                            st.markdown(f"### ğŸ“ å¯¹è¯è®°å½• {idx}")
                            if analysis_result["roles"].get("confidence", "low") != "high":
                                st.warning("âš ï¸ è¯¥å¯¹è¯çš„è§’è‰²è¯†åˆ«å¯ä¿¡åº¦ä¸é«˜ï¼Œè¯·æ ¸å®ã€‚")
                            st.markdown(f"**è§’è‰²è¯´æ˜ï¼š**")
                            st.markdown(f"- è¯´è¯è€…1 ({analysis_result['roles']['spk1']})")
                            st.markdown(f"- è¯´è¯è€…2 ({analysis_result['roles']['spk2']})")
                            st.markdown("**è¯¦ç»†å¯¹è¯ï¼š**")
                            st.markdown(analysis_result["formatted_text"])
                            st.markdown("---")
            
            with tab2:
                for idx, res in enumerate(results, 1):
                    if res["status"] == "success":
                        analysis_result = res["analysis_result"]
                        if analysis_result.get("status") == "success":
                            st.markdown(f"### ğŸ“Š åˆ†æç»“æœ {idx}")
                            st.markdown(analysis_result["analysis"])
                            st.markdown("---")
            
            # æ·»åŠ æ–°çš„æ±‡æ€»åˆ†ææ ‡ç­¾é¡µ
            with tab3:
                st.markdown("### ğŸ“ˆ æ±‡æ€»åˆ†ææŠ¥å‘Š")
                
                # æ˜¾ç¤ºå¤„ç†ä¸­çš„æç¤º
                with st.spinner('æ­£åœ¨ç”Ÿæˆæ±‡æ€»åˆ†ææŠ¥å‘Š...'):
                    summary_analysis = analyze_summary([res for res in results if res["status"] == "success"])
                
                # æ˜¾ç¤ºæ±‡æ€»åˆ†æç»“æœ
                st.markdown(summary_analysis)
            
            # ä¿®æ”¹ä¸‹è½½æŒ‰é’®ï¼ŒåŠ å…¥æ±‡æ€»åˆ†æ
            combined_report = ""
            for idx, res in enumerate(results, 1):
                if res["status"] == "success" and res["analysis_result"].get("status") == "success":
                    combined_report += f"\n\n{'='*50}\nå¯¹è¯è®°å½• {idx}ï¼š\n{'='*50}\n\n"
                    combined_report += res["analysis_result"]["formatted_text"]
                    combined_report += f"\n\n{'='*50}\nåˆ†æç»“æœ {idx}ï¼š\n{'='*50}\n\n"
                    combined_report += res["analysis_result"]["analysis"]
            
            combined_report += f"\n\n{'='*50}\næ±‡æ€»åˆ†ææŠ¥å‘Šï¼š\n{'='*50}\n\n"
            combined_report += summary_analysis
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†ææŠ¥å‘Š",
                data=combined_report,
                file_name="complete_analysis_report.txt",
                mime="text/plain"
            )

        except Exception as e:
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in temp_files:
                if os.path.exists(temp_file):
                    os.remove(temp_file)