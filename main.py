import streamlit as st
import os
import json
import time
import requests
import base64
import hashlib
import hmac
import urllib
from langchain_community.chat_models  import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage

# è®¯é£APIé…ç½®
lfasr_host = 'https://raasr.xfyun.cn/v2/api'
api_upload = '/upload'
api_get_result = '/getResult'
appid = "7fd8fde4"
secret_key = "ce4e08d9f1870b5a45dcedc60e99780f"


# è¯·æ±‚ç­¾åç”Ÿæˆ
def get_signa(appid, secret_key, ts):
    m2 = hashlib.md5()
    m2.update((appid + ts).encode('utf-8'))
    md5 = m2.hexdigest()
    md5 = bytes(md5, encoding='utf-8')
    signa = hmac.new(secret_key.encode('utf-8'), md5, hashlib.sha1).digest()
    signa = base64.b64encode(signa)
    signa = str(signa, 'utf-8')
    return signa


# ä¸Šä¼ æ–‡ä»¶åˆ°è®¯é£API
def upload_file_to_xunfei(upload_file_path):
    ts = str(int(time.time()))
    signa = get_signa(appid, secret_key, ts)

    file_len = os.path.getsize(upload_file_path)
    file_name = os.path.basename(upload_file_path)

    param_dict = {
        'appId': appid,
        'signa': signa,
        'ts': ts,
        'fileSize': file_len,
        'fileName': file_name,
        'duration': "200",
        'roleNum': 2,
        'roleType': 1
    }

    data = open(upload_file_path, 'rb').read(file_len)

    response = requests.post(url=lfasr_host + api_upload + "?" + urllib.parse.urlencode(param_dict),
                             headers={"Content-type": "application/json"}, data=data)
    result = json.loads(response.text)
    return result


# è·å–è½¬å†™ç»“æœ
def get_transcription_result(orderId):
    ts = str(int(time.time()))
    signa = get_signa(appid, secret_key, ts)

    param_dict = {
        'appId': appid,
        'signa': signa,
        'ts': ts,
        'orderId': orderId,
        'resultType': "transfer,predict"
    }

    status = 3
    while status == 3:
        response = requests.post(url=lfasr_host + api_get_result + "?" + urllib.parse.urlencode(param_dict),
                                 headers={"Content-type": "application/json"})
        result = json.loads(response.text)
        status = result['content']['orderInfo']['status']
        if status == 4:
            break
        time.sleep(5)
    return result


# è§„èŒƒåŒ–JSONæ–‡ä»¶ä¸ºå¯è¯»æ–‡æœ¬
def merge_result_for_one_vad(result_vad):
    content = []
    for rt_dic in result_vad['st']['rt']:
        spk_str = 'spk' + str(3 - int(result_vad['st']['rl'])) + '##'
        for st_dic in rt_dic['ws']:
            for cw_dic in st_dic['cw']:
                for w in cw_dic['w']:
                    spk_str += w
        spk_str += '\n'
        content.append(spk_str)
    return content


def content_to_file(content, output_file_path):
    with open(output_file_path, 'w', encoding='utf-8') as f:
        for lines in content:
            f.write(lines)


def identify_roles(raw_text: str) -> dict:
    """
    ä½¿ç”¨LLMè¯†åˆ«å¯¹è¯ä¸­çš„è§’è‰²

    Args:
        raw_text (str): åŸå§‹çš„å¸¦spkæ ‡è®°çš„æ–‡æœ¬

    Returns:
        dict: è§’è‰²æ˜ å°„å…³ç³»ï¼Œå¦‚ {'spk1': 'é”€å”®', 'spk2': 'å®¢æˆ·'}
    """
    # æå–å‰å‡ è½®å¯¹è¯ç”¨äºè§’è‰²åˆ¤æ–­
    lines = raw_text.strip().split('\n')
    sample_dialogue = '\n'.join(lines[:10])  # å–å‰10è¡Œè¿›è¡Œåˆ†æ

    llm = ChatOpenAI(
        openai_api_key="sk-gXeRXhgYsLFziprS93D5F6D31eE249D59235739b37Bd20B1",
        openai_api_base="https://openai.weavex.tech/v1",
        model_name="gpt-4o",
        temperature=0.2  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ç­”æ¡ˆ
    )

    system_prompt = """
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¯¹è¯åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œè¯†åˆ«å‡ºspk1å’Œspk2å„è‡ªçš„è§’è‰²ï¼ˆé”€å”®è¿˜æ˜¯å®¢æˆ·ï¼‰ã€‚
    
    åˆ¤æ–­ä¾æ®ï¼š
    1. è¯´è¯æ–¹å¼å’Œè¯­æ°”ï¼ˆé”€å”®é€šå¸¸æ›´ä¸»åŠ¨ã€æ›´æ­£å¼ï¼‰
    2. æé—®æ–¹å¼ï¼ˆé”€å”®å€¾å‘äºå¼•å¯¼æ€§æé—®ï¼‰
    3. ä¸“ä¸šæœ¯è¯­çš„ä½¿ç”¨ï¼ˆé”€å”®æ›´å¯èƒ½ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼‰
    4. ä¿¡æ¯è·å–æ–¹å‘ï¼ˆé”€å”®å€¾å‘äºè·å–å®¢æˆ·éœ€æ±‚ä¿¡æ¯ï¼‰
    
    è¯·åªè¿”å›å¦‚ä¸‹æ ¼å¼çš„JSONï¼š
    {
        "spk1": "é”€å”®/å®¢æˆ·",
        "spk2": "é”€å”®/å®¢æˆ·",
        "confidence": "high/medium/low"
    }
    """

    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"å¯¹è¯å†…å®¹ï¼š\n\n{sample_dialogue}")
    ])

    try:
        response = llm(prompt.format_messages())
        roles = json.loads(response.content)
        return roles
    except Exception as e:
        # å¦‚æœè¯†åˆ«å¤±è´¥ï¼Œè¿”å›é»˜è®¤æ˜ å°„
        return {
            "spk1": "æœªçŸ¥è§’è‰²1",
            "spk2": "æœªçŸ¥è§’è‰²2",
            "confidence": "low"
        }


def format_conversation(raw_text: str) -> tuple:
    """
    å°†åŸå§‹çš„spkæ ‡è®°æ–‡æœ¬è½¬æ¢ä¸ºæ›´è§„èŒƒçš„å¯¹è¯æ ¼å¼

    Returns:
        tuple: (formatted_text, roles_info)
    """
    # é¦–å…ˆè¯†åˆ«è§’è‰²
    roles = identify_roles(raw_text)

    lines = raw_text.strip().split('\n')
    formatted_lines = []
    current_speaker = None
    current_content = []

    for line in lines:
        if not line.strip() or '##' not in line:
            continue

        speaker, content = line.split('##')
        content = content.strip()

        if not content or content.strip().replace('ã€', '').isdigit():
            continue

        # ä½¿ç”¨è¯†åˆ«å‡ºçš„è§’è‰²
        speaker_role = roles.get(speaker, f"æœªçŸ¥è§’è‰²{speaker[-1]}")

        if speaker == current_speaker:
            current_content.append(content)
        else:
            if current_speaker and current_content:
                formatted_lines.append(f"{roles.get(current_speaker, f'æœªçŸ¥è§’è‰²{current_speaker[-1]}')}ï¼š{''.join(current_content)}")
            current_speaker = speaker
            current_content = [content]

    # å¤„ç†æœ€åä¸€ç»„å¯¹è¯
    if current_speaker and current_content:
        formatted_lines.append(f"{roles.get(current_speaker, f'æœªçŸ¥è§’è‰²{current_speaker[-1]}')}ï¼š{''.join(current_content)}")

    formatted_text = '\n\n'.join(formatted_lines)

    return formatted_text, roles


def analyze_conversation(conversation_text: str):
    """
    åˆ†æé€šè¯è®°å½•å¹¶æä¾›æ”¹è¿›å»ºè®®
    """
    # æ ¼å¼åŒ–å¯¹è¯æ–‡æœ¬å¹¶è·å–è§’è‰²ä¿¡æ¯
    formatted_text, roles = format_conversation(conversation_text)

    # å¦‚æœè§’è‰²è¯†åˆ«å¯ä¿¡åº¦ä½ï¼Œåœ¨åˆ†æç»“æœä¸­æé†’
    confidence_warning = ""
    if roles.get("confidence", "low") == "low":
        confidence_warning = "\n\n æ³¨æ„ï¼šç³»ç»Ÿå¯¹è¯´è¯è€…è§’è‰²çš„è¯†åˆ«å¯ä¿¡åº¦è¾ƒä½ï¼Œè¯·äººå·¥æ ¸å®ã€‚"

    # è°ƒæ•´system promptï¼ŒåŠ å…¥è§’è‰²ä¿¡æ¯
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é”€å”®é€šè¯åˆ†æä¸“å®¶ã€‚è¿™æ˜¯ä¸€æ®µå¯¹è¯è®°å½•ï¼Œå…¶ä¸­ï¼š
    - {roles['spk1']} çš„å‘è¨€ä»¥"{roles['spk1']}ï¼š"å¼€å¤´
    - {roles['spk2']} çš„å‘è¨€ä»¥"{roles['spk2']}ï¼š"å¼€å¤´
    
    è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œæ·±å…¥åˆ†æï¼š
    1. æ•´ä½“è¯„åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰ï¼š
       - å¼€åœºç™½è¡¨ç°ï¼ˆ20åˆ†ï¼‰
       - éœ€æ±‚æŒ–æ˜ï¼ˆ20åˆ†ï¼‰
       - äº§å“ä»‹ç»ï¼ˆ20åˆ†ï¼‰
       - å¼‚è®®å¤„ç†ï¼ˆ20åˆ†ï¼‰
       - æˆäº¤æŠ€å·§ï¼ˆ20åˆ†ï¼‰

    2. è¯¦ç»†åˆ†æï¼š
       a) å¯¹è¯èŠ‚å¥ä¸äº’åŠ¨
          - é”€å”®èŠ‚å¥æ§åˆ¶
          - å€¾å¬ä¸å›åº”è´¨é‡
          - è¯è¯­æƒæŠŠæ§
       
       b) é”€å”®æŠ€å·§åº”ç”¨
          - SPINæŠ€å·§è¿ç”¨
          - ä»·å€¼å±•ç¤ºèƒ½åŠ›
          - ä¿ƒæˆäº¤æŠ€å·§
       
       c) å®¢æˆ·æ„å‘è¯†åˆ«
          - å®¢æˆ·å…´è¶£ç‚¹
          - è´­ä¹°æ„æ„¿å¼ºåº¦
          - å†³ç­–å½±å“å› ç´ 

    3. å…·ä½“æ”¹è¿›å»ºè®®ï¼š
       - è‡³å°‘3ä¸ªå¯ç«‹å³æ‰§è¡Œçš„æ”¹è¿›ç‚¹
       - å»ºè®®çš„è¯æœ¯ç¤ºä¾‹
       - åç»­è·Ÿè¿›å»ºè®®

    è¯·ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œå¹¶çªå‡ºå…³é”®å‘ç°ã€‚
    """

    # é…ç½®OpenAI API
    llm = ChatOpenAI(
        openai_api_key="sk-gXeRXhgYsLFziprS93D5F6D31eE249D59235739b37Bd20B1",
        openai_api_base="https://openai.weavex.tech/v1",
        model_name="deepseek-r1",
        temperature=0.7
    )

    # åˆ›å»ºæç¤ºæ¨¡æ¿
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ä»¥ä¸‹æ˜¯éœ€è¦åˆ†æçš„é€šè¯è®°å½•ï¼š\n\n{formatted_text}")
    ])

    try:
        response = llm(prompt.format_messages())
        return {
            "status": "success",
            "analysis": response.content,
            "formatted_text": formatted_text,
            "roles": roles
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        }


# Streamlitç•Œé¢
st.set_page_config(
    page_title="åˆ†æé€šè¯è®°å½•Demo",
    page_icon="ğŸ“"
)

st.title("åˆ†æé€šè¯è®°å½•ï¼ˆDemoï¼‰ğŸ“")

uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ é€šè¯å½•éŸ³æ–‡ä»¶",
    type=['wav', 'mp3', 'm4a', 'ogg'],
    accept_multiple_files=True
)

if uploaded_files:
    st.write("å·²ä¸Šä¼ çš„æ–‡ä»¶:")
    for file in uploaded_files:
        st.write(f"- {file.name}")

    if st.button("å¼€å§‹åˆ†æ"):
        st.info("æ–‡ä»¶åˆ†æä¸­...")

        for uploaded_file in uploaded_files:
            with open(f"./temp_{uploaded_file.name}", "wb") as f:
                f.write(uploaded_file.getbuffer())

            result = upload_file_to_xunfei(f"./temp_{uploaded_file.name}")
            if 'content' in result and 'orderId' in result['content']:
                orderId = result['content']['orderId']
                transcription_result = get_transcription_result(orderId)

                # å¤„ç†è½¬å†™ç»“æœ
                if 'content' in transcription_result:
                    js_xunfei_result = json.loads(transcription_result['content']['orderResult'])
                    content = []
                    for result_one_vad_str in js_xunfei_result['lattice']:
                        js_result_one_vad = json.loads(result_one_vad_str['json_1best'])
                        content.extend(merge_result_for_one_vad(js_result_one_vad))

                    # è¾“å‡ºåˆ°æ–‡ä»¶
                    output_file_path = f"{uploaded_file.name}_output.txt"
                    content_to_file(content, output_file_path)

                    # è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œåˆ†æ
                    with open(output_file_path, 'r', encoding='utf-8') as f:
                        conversation_text = f.read()

                    # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æ
                    analysis_result = analyze_conversation(conversation_text)

                    if analysis_result["status"] == "success":
                        st.success(f"æ–‡ä»¶è½¬å†™å’Œåˆ†æå·²å®Œæˆï¼")

                        # ä½¿ç”¨tabsæ¥ç»„ç»‡å†…å®¹
                        tab1, tab2 = st.tabs(["ğŸ“ å¯¹è¯è®°å½•", "ğŸ“Š åˆ†æç»“æœ"])

                        with tab1:
                            # æ˜¾ç¤ºè§’è‰²è¯†åˆ«ä¿¡æ¯
                            if analysis_result["roles"].get("confidence") != "high":
                                st.warning(" ç³»ç»Ÿå¯¹è¯´è¯è€…è§’è‰²çš„è¯†åˆ«å¯ä¿¡åº¦ä¸é«˜ï¼Œè¯·æ ¸å®ã€‚", icon="âš ï¸")

                            st.markdown("### å¯¹è¯è§’è‰²")
                            st.markdown(f"- è¯´è¯è€…1 ({analysis_result['roles']['spk1']})")
                            st.markdown(f"- è¯´è¯è€…2 ({analysis_result['roles']['spk2']})")

                            st.markdown("### é€šè¯è®°å½•")
                            st.markdown(analysis_result["formatted_text"])

                        with tab2:
                            st.markdown("### ğŸ” é€šè¯åˆ†æç»“æœ")
                            st.markdown(analysis_result["analysis"])

                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†ææŠ¥å‘Š",
                            data=f"é€šè¯è®°å½•ï¼š\n\n{analysis_result['formatted_text']}\n\nåˆ†æç»“æœï¼š\n\n{analysis_result['analysis']}",
                            file_name=f"{uploaded_file.name}_analysis_report.txt",
                            mime="text/plain"
                        )
                    else:
                        st.error(f"åˆ†æè¿‡ç¨‹å‡ºç°é”™è¯¯ï¼š{analysis_result['message']}")
                        st.success(f"ä»…å®Œæˆæ–‡ä»¶è½¬å†™ï¼Œç»“æœå·²ä¿å­˜ä¸º: {output_file_path}")

                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    os.remove(f"./temp_{uploaded_file.name}")
                else:
                    st.error("æœªèƒ½æˆåŠŸè·å–è½¬å†™ç»“æœï¼")
            else:
                st.error("ä¸Šä¼ æ–‡ä»¶å¤±è´¥ï¼Œæ— æ³•è·å–è®¢å•IDï¼")
