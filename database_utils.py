"""
æ•°æ®åº“æ“ä½œå·¥å…·æ¨¡å—
æä¾›é€šè¯åˆ†æç³»ç»Ÿçš„æ‰€æœ‰æ•°æ®åº“æ“ä½œæ¥å£
"""
import asyncio
import json
from datetime import datetime, date
from typing import List, Dict, Optional, Tuple, Any
import asyncpg
from contextlib import asynccontextmanager
import pytz
import logging

logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­å›½æ—¶åŒº
CHINA_TZ = pytz.timezone('Asia/Shanghai')


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨ï¼Œå¤„ç†æ‰€æœ‰æ•°æ®åº“æ“ä½œ"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            config: æ•°æ®åº“é…ç½®å­—å…¸ï¼ˆæ¥è‡ªconfig.pyçš„DATABASE_CONFIGï¼‰
        """
        self.config = config
        self._pool: Optional[asyncpg.Pool] = None
        
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± å¹¶ç¡®ä¿æ•°æ®åº“ç»“æ„å®Œæ•´"""
        if self._pool is None:
            # è¿æ¥å‚æ•°ï¼Œæ·»åŠ æ—¶åŒºè®¾ç½®
            connect_kwargs = {
                'host': self.config['host'],
                'port': self.config['port'],
                'database': self.config['database'],
                'user': self.config['username'],
                'password': self.config['password'],
                'server_settings': {
                    'timezone': 'Asia/Shanghai',  # è®¾ç½®æœåŠ¡å™¨æ—¶åŒº
                    'jit': 'off',
                    'application_name': 'call_analysis_app'
                },
                **self.config.get('pool_config', {})
            }
            
            # åˆ›å»ºè¿æ¥æ± 
            self._pool = await asyncpg.create_pool(**connect_kwargs)
            logger.info("æ•°æ®åº“è¿æ¥æ± åˆ›å»ºæˆåŠŸ")
            
            # ç¡®ä¿æ•°æ®åº“ç»“æ„å®Œæ•´ï¼ˆåŒ…æ‹¬è§¦å‘å™¨ï¼‰
            await self._ensure_database_structure()
    
    async def _ensure_database_structure(self):
        """ç¡®ä¿æ•°æ®åº“ç»“æ„å®Œæ•´ï¼ŒåŒ…æ‹¬è¡¨ã€ç´¢å¼•å’Œè§¦å‘å™¨"""
        try:
            async with self.acquire() as conn:
                # æ£€æŸ¥å¹¶åˆ›å»ºè§¦å‘å™¨å‡½æ•°
                logger.info("ğŸ”§ æ£€æŸ¥æ•°æ®åº“è§¦å‘å™¨...")
                
                # æ£€æŸ¥ update_salesperson_activity å‡½æ•°æ˜¯å¦å­˜åœ¨
                function_exists = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT 1 FROM pg_proc 
                        WHERE proname = 'update_salesperson_activity'
                    )
                """)
                
                if not function_exists:
                    logger.info("ğŸ“ åˆ›å»ºé”€å”®äººå‘˜æ´»åŠ¨æ›´æ–°è§¦å‘å™¨å‡½æ•°...")
                    await conn.execute("""
                        CREATE OR REPLACE FUNCTION update_salesperson_activity()
                        RETURNS TRIGGER AS $$
                        BEGIN
                            -- å½“ daily_call_records è¡¨æœ‰æ’å…¥æˆ–æ›´æ–°æ“ä½œæ—¶ï¼Œ
                            -- è‡ªåŠ¨æ›´æ–°å¯¹åº”é”€å”®äººå‘˜çš„ updated_at å­—æ®µ
                            UPDATE salespersons 
                            SET updated_at = CURRENT_TIMESTAMP 
                            WHERE id = NEW.salesperson_id;
                            
                            RETURN NEW;
                        END;
                        $$ LANGUAGE 'plpgsql';
                    """)
                    logger.info("âœ… è§¦å‘å™¨å‡½æ•°åˆ›å»ºæˆåŠŸ")
                else:
                    logger.info("âœ… è§¦å‘å™¨å‡½æ•°å·²å­˜åœ¨")
                
                # æ£€æŸ¥è§¦å‘å™¨æ˜¯å¦å­˜åœ¨
                trigger_exists = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT 1 FROM information_schema.triggers 
                        WHERE trigger_name = 'update_salesperson_activity_trigger'
                        AND event_object_table = 'daily_call_records'
                    )
                """)
                
                if not trigger_exists:
                    logger.info("ğŸ“ åˆ›å»ºé”€å”®äººå‘˜æ´»åŠ¨æ›´æ–°è§¦å‘å™¨...")
                    await conn.execute("""
                        CREATE TRIGGER update_salesperson_activity_trigger
                            AFTER INSERT OR UPDATE ON daily_call_records
                            FOR EACH ROW 
                            EXECUTE FUNCTION update_salesperson_activity();
                    """)
                    logger.info("âœ… è§¦å‘å™¨åˆ›å»ºæˆåŠŸ")
                else:
                    logger.info("âœ… è§¦å‘å™¨å·²å­˜åœ¨")
                
                # éªŒè¯è§¦å‘å™¨æ˜¯å¦å·¥ä½œ
                await self._verify_trigger_functionality(conn)
                
        except Exception as e:
            logger.error(f"âŒ ç¡®ä¿æ•°æ®åº“ç»“æ„æ—¶å‡ºé”™: {str(e)}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç³»ç»Ÿç»§ç»­è¿è¡Œ
    
    async def _verify_trigger_functionality(self, conn):
        """éªŒè¯è§¦å‘å™¨åŠŸèƒ½æ˜¯å¦æ­£å¸¸"""
        try:
            # é™é»˜éªŒè¯ï¼šæ£€æŸ¥è§¦å‘å™¨æ˜¯å¦åœ¨ä¿¡æ¯æ¶æ„ä¸­æ­£ç¡®æ³¨å†Œ
            triggers = await conn.fetch("""
                SELECT trigger_name, event_manipulation, action_timing
                FROM information_schema.triggers
                WHERE trigger_name = 'update_salesperson_activity_trigger'
                AND event_object_table = 'daily_call_records'
            """)
            
            if triggers:
                events = [t['event_manipulation'] for t in triggers]
                if 'INSERT' in events and 'UPDATE' in events:
                    logger.info("âœ… è§¦å‘å™¨åŠŸèƒ½éªŒè¯é€šè¿‡")
                else:
                    logger.warning("âš ï¸  è§¦å‘å™¨å¯èƒ½é…ç½®ä¸å®Œæ•´")
            else:
                logger.warning("âš ï¸  è§¦å‘å™¨éªŒè¯å¤±è´¥")
                
        except Exception as e:
            logger.warning(f"âš ï¸  è§¦å‘å™¨éªŒè¯æ—¶å‡ºé”™: {str(e)}")
            # ä¸å½±å“ä¸»æµç¨‹
    
    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥æ± """
        if self._pool:
            await self._pool.close()
            self._pool = None
            logger.info("æ•°æ®åº“è¿æ¥æ± å·²å…³é—­")
    
    @asynccontextmanager
    async def acquire(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self._pool is None:
            await self.initialize()
        
        # ç±»å‹æ–­è¨€ï¼šç¡®ä¿ _pool ä¸ä¸º None
        assert self._pool is not None, "Database pool should be initialized"
        
        async with self._pool.acquire() as connection:
            # ç¡®ä¿æ¯ä¸ªè¿æ¥éƒ½ä½¿ç”¨æ­£ç¡®çš„æ—¶åŒº
            await connection.execute("SET timezone = 'Asia/Shanghai'")
            yield connection
    
    async def get_salespersons(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰é”€å”®äººå‘˜åˆ—è¡¨
        
        Returns:
            é”€å”®äººå‘˜åˆ—è¡¨ [{"id": 1, "name": "å¼ ä¸‰"}, ...]
        """
        async with self.acquire() as conn:
            rows = await conn.fetch(
                "SELECT id, name FROM salespersons ORDER BY name"
            )
            return [dict(row) for row in rows]
    
    async def get_salesperson_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®å§“åè·å–é”€å”®äººå‘˜ä¿¡æ¯
        
        Args:
            name: é”€å”®äººå‘˜å§“å
            
        Returns:
            é”€å”®äººå‘˜ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        async with self.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT id, name FROM salespersons WHERE name = $1",
                name
            )
            return dict(row) if row else None
    
    async def check_daily_record_exists(self, salesperson_id: int, upload_date: date) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šé”€å”®äººå‘˜åœ¨æŒ‡å®šæ—¥æœŸæ˜¯å¦å·²æœ‰è®°å½•
        
        Args:
            salesperson_id: é”€å”®äººå‘˜ID
            upload_date: ä¸Šä¼ æ—¥æœŸ
            
        Returns:
            å¦‚æœå­˜åœ¨è®°å½•è¿”å›Trueï¼Œå¦åˆ™False
        """
        async with self.acquire() as conn:
            result = await conn.fetchval(
                """
                SELECT EXISTS(
                    SELECT 1 FROM daily_call_records 
                    WHERE salesperson_id = $1 AND upload_date = $2
                )
                """,
                salesperson_id, upload_date
            )
            return result
    
    async def get_daily_record(self, salesperson_id: int, upload_date: date) -> Optional[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šé”€å”®äººå‘˜åœ¨æŒ‡å®šæ—¥æœŸçš„è®°å½•
        
        Args:
            salesperson_id: é”€å”®äººå‘˜ID
            upload_date: ä¸Šä¼ æ—¥æœŸ
            
        Returns:
            æ—¥å¸¸è®°å½•ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        async with self.acquire() as conn:
            row = await conn.fetchrow(
                """
                SELECT id, total_calls, effective_calls, average_score,
                       summary_analysis, improvement_suggestions, 
                       created_at
                FROM daily_call_records 
                WHERE salesperson_id = $1 AND upload_date = $2
                """,
                salesperson_id, upload_date
            )
            return dict(row) if row else None
    
    async def delete_daily_record_and_details(self, daily_record_id: int):
        """
        åˆ é™¤æ—¥å¸¸è®°å½•åŠå…¶æ‰€æœ‰ç›¸å…³çš„é€šè¯è¯¦æƒ…ï¼ˆçº§è”åˆ é™¤ï¼‰
        
        Args:
            daily_record_id: æ—¥å¸¸è®°å½•ID
        """
        async with self.acquire() as conn:
            # ç”±äºè®¾ç½®äº†ON DELETE CASCADEï¼Œåˆ é™¤daily_recordä¼šè‡ªåŠ¨åˆ é™¤ç›¸å…³çš„call_details
            await conn.execute(
                "DELETE FROM daily_call_records WHERE id = $1",
                daily_record_id
            )
            logger.info(f"å·²åˆ é™¤æ—¥å¸¸è®°å½•ID: {daily_record_id} åŠå…¶æ‰€æœ‰é€šè¯è¯¦æƒ…")
    
    async def create_daily_record(self, salesperson_id: int, upload_date: date) -> int:
        """
        åˆ›å»ºæ–°çš„æ—¥å¸¸è®°å½•ï¼ˆå®‰å…¨åˆ›å»ºï¼Œé˜²æ­¢é‡å¤ï¼‰
        
        Args:
            salesperson_id: é”€å”®äººå‘˜ID
            upload_date: ä¸Šä¼ æ—¥æœŸ
            
        Returns:
            æ–°åˆ›å»ºçš„è®°å½•IDæˆ–ç°æœ‰è®°å½•ID
        """
        async with self.acquire() as conn:
            # å…ˆå°è¯•è·å–ç°æœ‰è®°å½•ï¼Œé¿å…è¿åUNIQUEçº¦æŸ
            existing_record = await conn.fetchrow(
                """
                SELECT id FROM daily_call_records 
                WHERE salesperson_id = $1 AND upload_date = $2
                """,
                salesperson_id, upload_date
            )
            
            if existing_record:
                logger.warning(f"âš ï¸ æ—¥å¸¸è®°å½•å·²å­˜åœ¨: é”€å”®äººå‘˜ID {salesperson_id}, æ—¥æœŸ {upload_date}, è®°å½•ID {existing_record['id']}")
                return existing_record['id']
            
            # ä½¿ç”¨ ON CONFLICT å­å¥é˜²æ­¢é‡å¤æ’å…¥
            row = await conn.fetchrow(
                """
                INSERT INTO daily_call_records 
                (salesperson_id, upload_date, total_calls, effective_calls, created_at)
                VALUES ($1, $2, 0, 0, NOW() AT TIME ZONE 'Asia/Shanghai')
                ON CONFLICT (salesperson_id, upload_date) 
                DO UPDATE SET updated_at = CURRENT_TIMESTAMP
                RETURNING id
                """,
                salesperson_id, upload_date
            )
            
            logger.info(f"ğŸ“ å®‰å…¨åˆ›å»º/è·å–æ—¥å¸¸è®°å½•: é”€å”®äººå‘˜ID {salesperson_id}, æ—¥æœŸ {upload_date}, è®°å½•ID {row['id']}")
            return row['id']
    
    async def update_daily_record_stats(
        self, 
        daily_record_id: int,
        total_calls: int,
        effective_calls: int,
        average_score: Optional[float],
        summary_analysis: Optional[str],
        improvement_suggestions: Optional[str],
        merge_analysis: bool = False
    ):
        """
        æ›´æ–°æ—¥å¸¸è®°å½•çš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            daily_record_id: æ—¥å¸¸è®°å½•ID
            total_calls: æ€»é€šè¯æ•°
            effective_calls: æœ‰æ•ˆé€šè¯æ•°
            average_score: å¹³å‡è¯„åˆ†
            summary_analysis: æ±‡æ€»åˆ†æ
            improvement_suggestions: æ”¹è¿›å»ºè®®
            merge_analysis: æ˜¯å¦åˆå¹¶åˆ†æç»“æœï¼ˆè¿½åŠ æ¨¡å¼æ—¶ä½¿ç”¨ï¼‰
        """
        async with self.acquire() as conn:
            if merge_analysis:
                # è·å–ç°æœ‰çš„åˆ†æç»“æœ
                existing_record = await conn.fetchrow(
                    """
                    SELECT summary_analysis, improvement_suggestions, created_at,
                           total_calls, effective_calls, average_score
                    FROM daily_call_records 
                    WHERE id = $1
                    """,
                    daily_record_id
                )
                
                if existing_record:
                    # ç”Ÿæˆæ—¶é—´æˆ³
                    from datetime import datetime
                    current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
                    
                    # å‡†å¤‡è¯„åˆ†å†å²ä¿¡æ¯
                    score_history = ""
                    old_total = existing_record['total_calls'] or 0
                    old_effective = existing_record['effective_calls'] or 0
                    old_avg = existing_record['average_score']
                    
                    # è®¡ç®—æ–°å¢çš„é€šè¯æ•°æ®
                    new_calls = total_calls - old_total
                    new_effective = effective_calls - old_effective
                    
                    if old_total > 0 and new_calls > 0:
                        # ç±»å‹è½¬æ¢å’Œè®¡ç®—æ˜¾ç¤ºå€¼
                        old_avg_float = float(old_avg) if old_avg else None
                        current_avg_float = float(average_score) if average_score else None
                        
                        old_avg_display = f"{old_avg_float:.1f}" if old_avg_float else "N/A"
                        current_avg_display = f"{current_avg_float:.1f}" if current_avg_float else "N/A"
                        
                        # è®¡ç®—æ–°å¢éƒ¨åˆ†çš„å¹³å‡åˆ†
                        new_avg_display = "N/A"
                        if current_avg_float and old_avg_float and new_calls > 0:
                            new_avg = (current_avg_float * total_calls - old_avg_float * old_total) / new_calls
                            new_avg_display = f"{new_avg:.1f}"
                        
                        score_history = f"""
ğŸ“Š **è¯„åˆ†å†å²è¿½è¸ª**
â”œâ”€ åŸæœ‰è®°å½•ï¼š{old_total}ä¸ªé€šè¯ï¼Œ{old_effective}ä¸ªæœ‰æ•ˆï¼Œå¹³å‡åˆ† {old_avg_display}
â”œâ”€ æœ¬æ¬¡æ–°å¢ï¼š{new_calls}ä¸ªé€šè¯ï¼Œ{new_effective}ä¸ªæœ‰æ•ˆï¼Œå¹³å‡åˆ† {new_avg_display}
â””â”€ åˆå¹¶åï¼š{total_calls}ä¸ªé€šè¯ï¼Œ{effective_calls}ä¸ªæœ‰æ•ˆï¼Œå¹³å‡åˆ† {current_avg_display}

"""
                    
                    # åˆå¹¶æ±‡æ€»åˆ†æ
                    existing_summary = existing_record['summary_analysis'] or ''
                    if existing_summary and summary_analysis:
                        merged_summary = f"""{score_history}{existing_summary}

==================== è¿½åŠ åˆ†æ ({current_time}) ====================
æœ¬æ¬¡æ–°å¢é€šè¯çš„åˆ†æç»“æœï¼š

{summary_analysis}
==================== è¿½åŠ åˆ†æç»“æŸ ===================="""
                    else:
                        merged_summary = f"{score_history}{summary_analysis or existing_summary}"
                    
                    # åˆå¹¶æ”¹è¿›å»ºè®®
                    existing_suggestions = existing_record['improvement_suggestions'] or ''
                    if existing_suggestions and improvement_suggestions:
                        merged_suggestions = f"""{existing_suggestions}

--- åŸºäºæ–°å¢é€šè¯çš„è¡¥å……å»ºè®® ({current_time}) ---
{improvement_suggestions}"""
                    else:
                        merged_suggestions = improvement_suggestions or existing_suggestions
                    
                    # ä½¿ç”¨åˆå¹¶åçš„å†…å®¹
                    summary_analysis = merged_summary
                    improvement_suggestions = merged_suggestions
            
            # æ›´æ–°è®°å½•
            await conn.execute(
                """
                UPDATE daily_call_records 
                SET total_calls = $2,
                    effective_calls = $3,
                    average_score = $4,
                    summary_analysis = $5,
                    improvement_suggestions = $6,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = $1
                """,
                daily_record_id, total_calls, effective_calls, 
                average_score, summary_analysis, improvement_suggestions
            )
    
    async def update_image_call_statistics(
        self,
        daily_record_id: int,
        image_calls: int,
        image_effective_calls: int,
        reset_image_data: bool = False
    ):
        """
        æ›´æ–°æ—¥å¸¸è®°å½•ä¸­çš„å›¾ç‰‡é€šè¯ç»Ÿè®¡æ•°æ®
        
        Args:
            daily_record_id: æ—¥å¸¸è®°å½•ID
            image_calls: æ–°å¢å›¾ç‰‡é€šè¯æ•°
            image_effective_calls: æ–°å¢å›¾ç‰‡æœ‰æ•ˆé€šè¯æ•°
            reset_image_data: æ˜¯å¦é‡ç½®å›¾ç‰‡æ•°æ®ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
        """
        async with self.acquire() as conn:
            # ğŸ”§ ä¸´æ—¶ä¿®å¤ï¼šæ£€æŸ¥image_callså­—æ®µæ˜¯å¦å­˜åœ¨
            image_fields_exist = await conn.fetchval("""
                SELECT COUNT(*) FROM information_schema.columns 
                WHERE table_name = 'daily_call_records' 
                AND column_name = 'image_calls'
                AND table_schema = 'public'
            """)
            
            if image_fields_exist > 0:
                # åŸå§‹é€»è¾‘ï¼šä½¿ç”¨ä¸“é—¨çš„å›¾ç‰‡å­—æ®µ
                if reset_image_data:
                    # è¦†ç›–æ¨¡å¼ï¼šç›´æ¥è®¾ç½®ä¸ºæ–°å€¼
                    await conn.execute(
                        """
                        UPDATE daily_call_records 
                        SET image_calls = $2,
                            image_effective_calls = $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = $1
                        """,
                        daily_record_id, image_calls, image_effective_calls
                    )
                    logger.info(f"ğŸ“Š é‡ç½®å›¾ç‰‡ç»Ÿè®¡: è®°å½•ID {daily_record_id}, å›¾ç‰‡é€šè¯ {image_calls}, æœ‰æ•ˆ {image_effective_calls}")
                else:
                    # è¿½åŠ æ¨¡å¼ï¼šç´¯åŠ ç°æœ‰å€¼
                    await conn.execute(
                        """
                        UPDATE daily_call_records 
                        SET image_calls = COALESCE(image_calls, 0) + $2,
                            image_effective_calls = COALESCE(image_effective_calls, 0) + $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = $1
                        """,
                        daily_record_id, image_calls, image_effective_calls
                    )
                    logger.info(f"ğŸ“Š ç´¯åŠ å›¾ç‰‡ç»Ÿè®¡: è®°å½•ID {daily_record_id}, æ–°å¢å›¾ç‰‡é€šè¯ {image_calls}, æ–°å¢æœ‰æ•ˆ {image_effective_calls}")
                
                # ğŸ”§ ä¿®å¤ï¼šä¸å†é‡æ–°è®¡ç®—æ€»è®¡å­—æ®µï¼Œé¿å…è¦†ç›– update_daily_record_stats è®¾ç½®çš„æ­£ç¡®å€¼
                # æ€»è®¡å­—æ®µï¼ˆtotal_calls, effective_callsï¼‰å·²ç»åœ¨ update_daily_record_stats ä¸­æ­£ç¡®å¤„ç†
                logger.info(f"ğŸ“Š å›¾ç‰‡åˆ†ç±»ç»Ÿè®¡å­—æ®µæ›´æ–°å®Œæˆï¼ˆæ€»è®¡å­—æ®µä¿æŒä¸å˜ï¼‰")
            else:
                # ğŸš¨ å›é€€é€»è¾‘ï¼šå›¾ç‰‡å­—æ®µä¸å­˜åœ¨ï¼Œç›´æ¥æ›´æ–°æ€»å­—æ®µ
                logger.warning(f"âš ï¸ å›¾ç‰‡ç»Ÿè®¡å­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨å›é€€é€»è¾‘æ›´æ–°æ€»è®¡å­—æ®µ")
                
                if reset_image_data:
                    # è¦†ç›–æ¨¡å¼ï¼šç›´æ¥è®¾ç½®ä¸ºæ–°å€¼ï¼ˆè¿™åœ¨å›é€€æ¨¡å¼ä¸‹ä¸å®‰å…¨ï¼Œæ”¹ä¸ºè¿½åŠ ï¼‰
                    logger.warning(f"âš ï¸ å›é€€æ¨¡å¼ä¸‹ä¸æ”¯æŒè¦†ç›–ï¼Œæ”¹ä¸ºè¿½åŠ æ¨¡å¼")
                    await conn.execute(
                        """
                        UPDATE daily_call_records 
                        SET total_calls = COALESCE(total_calls, 0) + $2,
                            effective_calls = COALESCE(effective_calls, 0) + $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = $1
                        """,
                        daily_record_id, image_calls, image_effective_calls
                    )
                else:
                    # è¿½åŠ æ¨¡å¼ï¼šç›´æ¥ç´¯åŠ åˆ°æ€»å­—æ®µ
                    await conn.execute(
                        """
                        UPDATE daily_call_records 
                        SET total_calls = COALESCE(total_calls, 0) + $2,
                            effective_calls = COALESCE(effective_calls, 0) + $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = $1
                        """,
                        daily_record_id, image_calls, image_effective_calls
                    )
                
                logger.info(f"ğŸ“Š å›é€€æ¨¡å¼ï¼šç´¯åŠ åˆ°æ€»è®¡: è®°å½•ID {daily_record_id}, æ–°å¢é€šè¯ {image_calls}, æ–°å¢æœ‰æ•ˆ {image_effective_calls}")
    
    async def update_audio_call_statistics(
        self,
        daily_record_id: int,
        audio_calls: int,
        audio_effective_calls: int,
        reset_audio_data: bool = False
    ):
        """
        æ›´æ–°æ—¥å¸¸è®°å½•ä¸­çš„éŸ³é¢‘é€šè¯ç»Ÿè®¡æ•°æ®
        
        Args:
            daily_record_id: æ—¥å¸¸è®°å½•ID
            audio_calls: æ–°å¢éŸ³é¢‘é€šè¯æ•°
            audio_effective_calls: æ–°å¢éŸ³é¢‘æœ‰æ•ˆé€šè¯æ•°
            reset_audio_data: æ˜¯å¦é‡ç½®éŸ³é¢‘æ•°æ®ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
        """
        async with self.acquire() as conn:
            # æ£€æŸ¥audio_callså­—æ®µæ˜¯å¦å­˜åœ¨
            audio_fields_exist = await conn.fetchval("""
                SELECT COUNT(*) FROM information_schema.columns 
                WHERE table_name = 'daily_call_records' 
                AND column_name = 'audio_calls'
                AND table_schema = 'public'
            """)
            
            if audio_fields_exist > 0:
                # åŸå§‹é€»è¾‘ï¼šä½¿ç”¨ä¸“é—¨çš„éŸ³é¢‘å­—æ®µ
                if reset_audio_data:
                    # è¦†ç›–æ¨¡å¼ï¼šç›´æ¥è®¾ç½®ä¸ºæ–°å€¼
                    await conn.execute(
                        """
                        UPDATE daily_call_records 
                        SET audio_calls = $2,
                            audio_effective_calls = $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = $1
                        """,
                        daily_record_id, audio_calls, audio_effective_calls
                    )
                    logger.info(f"ğŸµ é‡ç½®éŸ³é¢‘ç»Ÿè®¡: è®°å½•ID {daily_record_id}, éŸ³é¢‘é€šè¯ {audio_calls}, æœ‰æ•ˆ {audio_effective_calls}")
                else:
                    # è¿½åŠ æ¨¡å¼ï¼šç´¯åŠ ç°æœ‰å€¼
                    await conn.execute(
                        """
                        UPDATE daily_call_records 
                        SET audio_calls = COALESCE(audio_calls, 0) + $2,
                            audio_effective_calls = COALESCE(audio_effective_calls, 0) + $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = $1
                        """,
                        daily_record_id, audio_calls, audio_effective_calls
                    )
                    logger.info(f"ğŸµ ç´¯åŠ éŸ³é¢‘ç»Ÿè®¡: è®°å½•ID {daily_record_id}, æ–°å¢éŸ³é¢‘é€šè¯ {audio_calls}, æ–°å¢æœ‰æ•ˆ {audio_effective_calls}")
                
                # ğŸ”§ ä¿®å¤ï¼šä¸å†é‡æ–°è®¡ç®—æ€»è®¡å­—æ®µï¼Œé¿å…è¦†ç›– update_daily_record_stats è®¾ç½®çš„æ­£ç¡®å€¼
                # æ€»è®¡å­—æ®µï¼ˆtotal_calls, effective_callsï¼‰å·²ç»åœ¨ update_daily_record_stats ä¸­æ­£ç¡®å¤„ç†
                logger.info(f"ğŸµ éŸ³é¢‘åˆ†ç±»ç»Ÿè®¡å­—æ®µæ›´æ–°å®Œæˆï¼ˆæ€»è®¡å­—æ®µä¿æŒä¸å˜ï¼‰")
            else:
                # å›é€€é€»è¾‘ï¼šéŸ³é¢‘å­—æ®µä¸å­˜åœ¨ï¼Œç›´æ¥æ›´æ–°æ€»å­—æ®µ
                logger.warning(f"âš ï¸ éŸ³é¢‘ç»Ÿè®¡å­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨å›é€€é€»è¾‘æ›´æ–°æ€»è®¡å­—æ®µ")
                
                if reset_audio_data:
                    # è¦†ç›–æ¨¡å¼ï¼šç›´æ¥è®¾ç½®ä¸ºæ–°å€¼ï¼ˆè¿™åœ¨å›é€€æ¨¡å¼ä¸‹ä¸å®‰å…¨ï¼Œæ”¹ä¸ºè¿½åŠ ï¼‰
                    logger.warning(f"âš ï¸ å›é€€æ¨¡å¼ä¸‹ä¸æ”¯æŒè¦†ç›–ï¼Œæ”¹ä¸ºè¿½åŠ æ¨¡å¼")
                
                # è¿½åŠ æ¨¡å¼ï¼šç›´æ¥ç´¯åŠ åˆ°æ€»å­—æ®µ
                await conn.execute(
                    """
                    UPDATE daily_call_records 
                    SET total_calls = COALESCE(total_calls, 0) + $2,
                        effective_calls = COALESCE(effective_calls, 0) + $3,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = $1
                    """,
                    daily_record_id, audio_calls, audio_effective_calls
                )
                
                logger.info(f"ğŸµ å›é€€æ¨¡å¼ï¼šç´¯åŠ åˆ°æ€»è®¡: è®°å½•ID {daily_record_id}, æ–°å¢é€šè¯ {audio_calls}, æ–°å¢æœ‰æ•ˆ {audio_effective_calls}")
    
    async def insert_call_detail(
        self,
        daily_record_id: int,
        salesperson_id: int,
        call_data: Dict[str, Any],
        record_type: str = 'audio'
    ):
        """
        æ’å…¥å•æ¡é€šè¯è¯¦æƒ…è®°å½•
        
        Args:
            daily_record_id: æ—¥å¸¸è®°å½•ID
            salesperson_id: é”€å”®äººå‘˜ID
            call_data: é€šè¯æ•°æ®å­—å…¸ï¼ŒåŒ…å«ï¼š
                - original_filename: åŸå§‹æ–‡ä»¶å
                - company_name: å…¬å¸åç§°
                - contact_person: è”ç³»äºº
                - phone_number: ç”µè¯å·ç 
                - conversation_text: å¯¹è¯æ–‡æœ¬
                - analysis_text: å®Œæ•´åˆ†ææ–‡æœ¬
                - score: é€šè¯è¯„åˆ†
                - is_effective: æ˜¯å¦æœ‰æ•ˆ
                - suggestions: æ”¹è¿›å»ºè®®
            record_type: è®°å½•ç±»å‹ï¼Œ'audio' æˆ– 'image'ï¼Œé»˜è®¤ 'audio'
        """
        async with self.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO call_details (
                    daily_record_id, salesperson_id, original_filename,
                    company_name, contact_person, phone_number,
                    conversation_text, analysis_text, 
                    score, is_effective, suggestions, record_type,
                    created_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, NOW() AT TIME ZONE 'Asia/Shanghai')
                """,
                daily_record_id, salesperson_id,
                call_data.get('original_filename'),
                call_data.get('company_name'),
                call_data.get('contact_person'),
                call_data.get('phone_number'),
                call_data.get('conversation_text'),
                call_data.get('analysis_text'),
                call_data.get('score'),
                call_data.get('is_effective', False),
                call_data.get('suggestions'),
                record_type
            )
    
    async def batch_insert_call_details(
        self,
        daily_record_id: int,
        salesperson_id: int,
        call_data_list: List[Dict[str, Any]],
        record_type: str = 'audio'
    ):
        """
        æ‰¹é‡æ’å…¥é€šè¯è¯¦æƒ…è®°å½•
        
        Args:
            daily_record_id: æ—¥å¸¸è®°å½•ID
            salesperson_id: é”€å”®äººå‘˜ID
            call_data_list: é€šè¯æ•°æ®åˆ—è¡¨
            record_type: è®°å½•ç±»å‹ï¼Œ'audio' æˆ– 'image'ï¼Œé»˜è®¤ 'audio'
        """
        async with self.acquire() as conn:
            # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
            values = []
            for call_data in call_data_list:
                values.append((
                    daily_record_id,
                    salesperson_id,
                    call_data.get('original_filename'),
                    call_data.get('company_name'),
                    call_data.get('contact_person'),
                    call_data.get('phone_number'),
                    call_data.get('conversation_text'),
                    call_data.get('analysis_text'),
                    call_data.get('score'),
                    call_data.get('is_effective', False),
                    call_data.get('suggestions'),
                    record_type
                ))
            
            # æ‰§è¡Œæ‰¹é‡æ’å…¥
            await conn.executemany(
                """
                INSERT INTO call_details (
                    daily_record_id, salesperson_id, original_filename,
                    company_name, contact_person, phone_number,
                    conversation_text, analysis_text, 
                    score, is_effective, suggestions, record_type,
                    created_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, NOW() AT TIME ZONE 'Asia/Shanghai')
                """,
                values
            )
            logger.info(f"æ‰¹é‡æ’å…¥äº† {len(values)} æ¡ {record_type} ç±»å‹çš„é€šè¯è¯¦æƒ…è®°å½•")
    
    async def check_duplicate_filenames(
        self, 
        salesperson_id: int, 
        filenames: List[str],
        days_back: int = 30
    ) -> Dict[str, Any]:
        """
        æ£€æµ‹é‡å¤æ–‡ä»¶åï¼ˆå®Œå…¨åŒ¹é…ï¼‰
        
        Args:
            salesperson_id: é”€å”®äººå‘˜ID
            filenames: è¦æ£€æµ‹çš„æ–‡ä»¶ååˆ—è¡¨
            days_back: æ£€æµ‹æœ€è¿‘å¤šå°‘å¤©çš„è®°å½•ï¼Œé»˜è®¤30å¤©
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸ï¼š
            {
                "duplicates": [
                    {
                        "filename": "æ–‡ä»¶å.mp3",
                        "last_upload_date": "2024-01-15",
                        "days_ago": 3
                    }
                ],
                "new_files": ["æ–°æ–‡ä»¶1.mp3", "æ–°æ–‡ä»¶2.aac"]
            }
        """
        async with self.acquire() as conn:
            if not filenames:
                return {"duplicates": [], "new_files": []}
            
            # æŸ¥è¯¢è¯¥é”€å”®å‘˜æœ€è¿‘æŒ‡å®šå¤©æ•°å†…çš„æ‰€æœ‰æ–‡ä»¶å
            existing_files = await conn.fetch(
                """
                SELECT original_filename, created_at::date as upload_date
                FROM call_details 
                WHERE salesperson_id = $1 
                AND original_filename = ANY($2)
                AND created_at >= NOW() - INTERVAL '%s days'
                ORDER BY created_at DESC
                """ % days_back,
                salesperson_id, filenames
            )
            
            # æ„å»ºç°æœ‰æ–‡ä»¶åçš„å­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åï¼Œå€¼ä¸ºä¸Šä¼ æ—¥æœŸ
            existing_files_dict = {}
            for existing_file in existing_files:
                filename = existing_file['original_filename']
                upload_date = existing_file['upload_date']
                # å¦‚æœåŒä¸€æ–‡ä»¶åæœ‰å¤šæ¬¡ä¸Šä¼ ï¼Œä¿ç•™æœ€è¿‘çš„ä¸€æ¬¡
                if filename not in existing_files_dict or upload_date > existing_files_dict[filename]:
                    existing_files_dict[filename] = upload_date
            
            # åˆ†ç±»æ–‡ä»¶ï¼šé‡å¤ vs æ–°æ–‡ä»¶
            duplicates = []
            new_files = []
            
            today = date.today()
            
            for filename in filenames:
                if filename in existing_files_dict:
                    last_upload_date = existing_files_dict[filename]
                    days_ago = (today - last_upload_date).days
                    duplicates.append({
                        "filename": filename,
                        "last_upload_date": last_upload_date.strftime("%Y-%m-%d"),
                        "days_ago": days_ago
                    })
                else:
                    new_files.append(filename)
            
            logger.info(f"ğŸ” æ–‡ä»¶é‡å¤æ£€æµ‹å®Œæˆ - é”€å”®å‘˜ID: {salesperson_id}")
            logger.info(f"   æ£€æµ‹èŒƒå›´: æœ€è¿‘ {days_back} å¤©")
            logger.info(f"   æ€»æ–‡ä»¶æ•°: {len(filenames)}")
            logger.info(f"   é‡å¤æ–‡ä»¶: {len(duplicates)} ä¸ª")
            logger.info(f"   æ–°æ–‡ä»¶: {len(new_files)} ä¸ª")
            
            return {
                "duplicates": duplicates,
                "new_files": new_files
            }

    async def get_recent_call_records(
        self, 
        salesperson_id: int, 
        days_back: int = 30,
        record_type: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–æœ€è¿‘çš„é€šè¯è®°å½•ï¼ˆç”¨äºæ™ºèƒ½å»é‡æ¯”è¾ƒï¼‰
        
        Args:
            salesperson_id: é”€å”®äººå‘˜ID
            days_back: è·å–æœ€è¿‘å¤šå°‘å¤©çš„è®°å½•ï¼Œé»˜è®¤30å¤©
            record_type: è®°å½•ç±»å‹ç­›é€‰ ('audio', 'image', Noneè¡¨ç¤ºå…¨éƒ¨)
            
        Returns:
            é€šè¯è®°å½•åˆ—è¡¨ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - id: è®°å½•ID
            - original_filename: æ–‡ä»¶å
            - company_name: å…¬å¸åç§°
            - contact_person: è”ç³»äºº
            - phone_number: ç”µè¯å·ç 
            - conversation_text: é€šè¯æ—¶é—´ä¿¡æ¯
            - analysis_text: é€šè¯ç»Ÿè®¡ä¿¡æ¯
            - is_effective: æ˜¯å¦æœ‰æ•ˆé€šè¯
            - created_at: åˆ›å»ºæ—¶é—´
        """
        async with self.acquire() as conn:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query_conditions = [
                "salesperson_id = $1",
                "created_at >= NOW() - INTERVAL '%s days'" % days_back
            ]
            
            # æ·»åŠ è®°å½•ç±»å‹ç­›é€‰
            if record_type:
                query_conditions.append("record_type = $2")
            
            # æ„å»ºæŸ¥è¯¢SQL
            query = f"""
                SELECT 
                    id,
                    original_filename,
                    company_name,
                    contact_person,
                    phone_number,
                    conversation_text,
                    analysis_text,
                    is_effective,
                    created_at,
                    record_type
                FROM call_details 
                WHERE {' AND '.join(query_conditions)}
                ORDER BY created_at DESC
            """
            
            # æ‰§è¡ŒæŸ¥è¯¢
            if record_type:
                records = await conn.fetch(query, salesperson_id, record_type)
            else:
                records = await conn.fetch(query, salesperson_id)
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            call_records = []
            for record in records:
                call_records.append({
                    'id': record['id'],
                    'original_filename': record['original_filename'],
                    'company_name': record['company_name'],
                    'contact_person': record['contact_person'], 
                    'phone_number': record['phone_number'],
                    'conversation_text': record['conversation_text'],
                    'analysis_text': record['analysis_text'],
                    'is_effective': record['is_effective'],
                    'created_at': record['created_at'],
                    'record_type': record['record_type']
                })
            
            logger.info(f"ğŸ” è·å–æœ€è¿‘é€šè¯è®°å½• - é”€å”®å‘˜ID: {salesperson_id}")
            logger.info(f"   æŸ¥è¯¢èŒƒå›´: æœ€è¿‘ {days_back} å¤©")
            logger.info(f"   è®°å½•ç±»å‹: {record_type or 'å…¨éƒ¨'}")
            logger.info(f"   è·å–è®°å½•æ•°: {len(call_records)}")
            
            return call_records


# åˆ›å»ºå…¨å±€æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ï¼ˆéœ€è¦åœ¨ä½¿ç”¨å‰é…ç½®ï¼‰
db_manager: Optional[DatabaseManager] = None


def setup_database(config: Dict[str, Any]) -> DatabaseManager:
    """
    è®¾ç½®æ•°æ®åº“ç®¡ç†å™¨
    
    Args:
        config: æ•°æ®åº“é…ç½®
        
    Returns:
        é…ç½®å¥½çš„æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
    """
    global db_manager
    db_manager = DatabaseManager(config)
    return db_manager


# Streamlitä¸“ç”¨çš„åŒæ­¥æ¥å£
class SyncDatabaseManager:
    """ä¸ºStreamlitæä¾›çš„åŒæ­¥æ•°æ®åº“æ¥å£"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
    def _run_async(self, coro_factory):
        """åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥ä»£ç ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        import asyncio
        import time
        
        # é‡è¯•é…ç½®
        max_retries = 3
        retry_delay = 2  # ç§’
        
        for attempt in range(max_retries):
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    # æ¯æ¬¡é‡è¯•éƒ½åˆ›å»ºæ–°çš„åç¨‹å¯¹è±¡
                    coro = coro_factory()
                    return loop.run_until_complete(coro)
                finally:
                    loop.close()
                    asyncio.set_event_loop(None)
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"è¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    logger.error(f"è¿æ¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise
    
    def get_salespersons(self) -> List[Dict[str, Any]]:
        """åŒæ­¥è·å–é”€å”®äººå‘˜åˆ—è¡¨"""
        def _get():
            async def _async_get():
                db = DatabaseManager(self.config)
                await db.initialize()
                try:
                    return await db.get_salespersons()
                finally:
                    await db.close()
            return _async_get()
        
        return self._run_async(_get)
    
    def check_daily_record_exists(self, salesperson_id: int, upload_date: date) -> bool:
        """åŒæ­¥æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨"""
        def _check():
            async def _async_check():
                db = DatabaseManager(self.config)
                await db.initialize()
                try:
                    return await db.check_daily_record_exists(salesperson_id, upload_date)
                finally:
                    await db.close()
            return _async_check()
        
        return self._run_async(_check)
    
    def check_duplicate_filenames(
        self, 
        salesperson_id: int, 
        filenames: List[str],
        days_back: int = 30
    ) -> Dict[str, Any]:
        """åŒæ­¥æ£€æµ‹é‡å¤æ–‡ä»¶å"""
        def _check():
            async def _async_check():
                db = DatabaseManager(self.config)
                await db.initialize()
                try:
                    return await db.check_duplicate_filenames(salesperson_id, filenames, days_back)
                finally:
                    await db.close()
            return _async_check()
        
        return self._run_async(_check)
    
    def get_recent_call_records(
        self, 
        salesperson_id: int, 
        days_back: int = 30,
        record_type: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """åŒæ­¥è·å–æœ€è¿‘çš„é€šè¯è®°å½•"""
        def _get():
            async def _async_get():
                db = DatabaseManager(self.config)
                await db.initialize()
                try:
                    return await db.get_recent_call_records(salesperson_id, days_back, record_type)
                finally:
                    await db.close()
            return _async_get()
        
        return self._run_async(_get)
    
    def save_analysis_data(
        self,
        salesperson_id: int,
        call_details_list: List[Dict[str, Any]],
        summary_analysis: str,
        upload_choice: Optional[str] = None
    ) -> bool:
        """åŒæ­¥ä¿å­˜åˆ†ææ•°æ®"""
        def _save():
            async def _async_save():
                db = DatabaseManager(self.config)
                await db.initialize()
                try:
                    today = date.today()
                    
                    # å®‰å…¨æ£€æŸ¥ï¼šè®°å½•å½“å‰æ“ä½œä¿¡æ¯
                    logger.info(f"ğŸ”„ å¼€å§‹ä¿å­˜åˆ†ææ•°æ®:")
                    logger.info(f"   é”€å”®äººå‘˜ID: {salesperson_id}")
                    logger.info(f"   ä¸Šä¼ æ—¥æœŸ: {today}")
                    logger.info(f"   é€šè¯æ•°é‡: {len(call_details_list)}")
                    logger.info(f"   æ“ä½œæ¨¡å¼: {upload_choice}")
                    
                    # ä½¿ç”¨å±€éƒ¨å˜é‡æ¥é¿å…é‡æ–°èµ‹å€¼é—®é¢˜
                    current_upload_choice = upload_choice
                    
                    # æŸ¥è¯¢å½“å‰æ•°æ®åº“ä¸­çš„è®°å½•æ•°é‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                    async with db.acquire() as conn:
                        total_records_before = await conn.fetchval("SELECT COUNT(*) FROM daily_call_records")
                        total_details_before = await conn.fetchval("SELECT COUNT(*) FROM call_details")
                        logger.info(f"ğŸ“Š æ“ä½œå‰æ•°æ®åº“çŠ¶æ€:")
                        logger.info(f"   æ¯æ—¥è®°å½•æ€»æ•°: {total_records_before}")
                        logger.info(f"   é€šè¯è¯¦æƒ…æ€»æ•°: {total_details_before}")
                    
                    # å¤„ç†ç°æœ‰è®°å½•
                    existing_record = await db.get_daily_record(salesperson_id, today)
                    if current_upload_choice == "overwrite" and existing_record:
                        # å®‰å…¨æ£€æŸ¥ï¼šç¡®è®¤åªåˆ é™¤æŒ‡å®šé”€å”®äººå‘˜å½“å¤©çš„è®°å½•
                        logger.warning(f"âš ï¸  å‡†å¤‡åˆ é™¤é”€å”®äººå‘˜ {salesperson_id} åœ¨ {today} çš„ç°æœ‰è®°å½•")
                        logger.warning(f"   å³å°†åˆ é™¤çš„è®°å½•ID: {existing_record['id']}")
                        
                        # æŸ¥è¯¢å°†è¦åˆ é™¤çš„è¯¦æƒ…æ•°é‡
                        async with db.acquire() as conn:
                            details_to_delete = await conn.fetchval(
                                "SELECT COUNT(*) FROM call_details WHERE daily_record_id = $1",
                                existing_record['id']
                            )
                        logger.warning(f"   å°†åˆ é™¤ {details_to_delete} æ¡é€šè¯è¯¦æƒ…")
                        
                        # æ‰§è¡Œåˆ é™¤æ“ä½œ
                        await db.delete_daily_record_and_details(existing_record['id'])
                        
                        # éªŒè¯åˆ é™¤åçš„çŠ¶æ€
                        async with db.acquire() as conn:
                            total_records_after_delete = await conn.fetchval("SELECT COUNT(*) FROM daily_call_records")
                            total_details_after_delete = await conn.fetchval("SELECT COUNT(*) FROM call_details")
                            logger.info(f"âœ… åˆ é™¤åæ•°æ®åº“çŠ¶æ€:")
                            logger.info(f"   æ¯æ—¥è®°å½•æ€»æ•°: {total_records_after_delete} (å‡å°‘: {total_records_before - total_records_after_delete})")
                            logger.info(f"   é€šè¯è¯¦æƒ…æ€»æ•°: {total_details_after_delete} (å‡å°‘: {total_details_before - total_details_after_delete})")
                        
                        # å®‰å…¨æ£€æŸ¥ï¼šç¡®è®¤åˆ é™¤çš„æ•°é‡åˆç†
                        if (total_records_before - total_records_after_delete) > 1:
                            logger.error(f"âŒ å¼‚å¸¸ï¼šåˆ é™¤äº†è¶…è¿‡1æ¡æ¯æ—¥è®°å½•ï¼")
                            raise Exception("åˆ é™¤æ“ä½œå¼‚å¸¸ï¼šåˆ é™¤çš„è®°å½•æ•°é‡è¶…å‡ºé¢„æœŸ")
                        
                        existing_record = None  # é‡ç½®ç°æœ‰è®°å½•çŠ¶æ€
                    
                    # è·å–æˆ–åˆ›å»ºæ—¥å¸¸è®°å½•
                    if existing_record and current_upload_choice == "append":
                        daily_record_id = existing_record['id']
                        logger.info(f"ğŸ“ ä½¿ç”¨ç°æœ‰è®°å½• (è¿½åŠ æ¨¡å¼): ID {daily_record_id}")
                    elif existing_record and current_upload_choice is None:
                        # å¦‚æœå­˜åœ¨è®°å½•ä½†æ²¡æœ‰æŒ‡å®šæ“ä½œæ¨¡å¼ï¼Œé»˜è®¤ä½¿ç”¨è¿½åŠ æ¨¡å¼
                        daily_record_id = existing_record['id']
                        logger.info(f"ğŸ“ ä½¿ç”¨ç°æœ‰è®°å½• (é»˜è®¤è¿½åŠ æ¨¡å¼): ID {daily_record_id}")
                        current_upload_choice = "append"  # è®¾ç½®ä¸ºè¿½åŠ æ¨¡å¼ä»¥ä¾¿åç»­é€»è¾‘å¤„ç†
                    else:
                        # åˆ›å»ºæ–°è®°å½•ï¼ˆæ²¡æœ‰ç°æœ‰è®°å½•æˆ–è¦†ç›–æ¨¡å¼åˆ é™¤åï¼‰
                        daily_record_id = await db.create_daily_record(salesperson_id, today)
                        logger.info(f"ğŸ“ åˆ›å»ºæ–°è®°å½•: ID {daily_record_id}")
                        # å¦‚æœæ˜¯æ–°åˆ›å»ºçš„è®°å½•ï¼Œé‡æ–°è·å–å®Œæ•´ä¿¡æ¯ä»¥ä¾¿åç»­ä½¿ç”¨
                        if current_upload_choice == "append":
                            # è¿½åŠ æ¨¡å¼ä½†æ²¡æœ‰ç°æœ‰è®°å½•çš„æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œè®°å½•è­¦å‘Š
                            logger.warning("âš ï¸  è¿½åŠ æ¨¡å¼ä½†æ²¡æœ‰æ‰¾åˆ°ç°æœ‰è®°å½•ï¼Œåˆ›å»ºäº†æ–°è®°å½•")
                            existing_record = None
                    
                    # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
                    total_calls = len(call_details_list)
                    effective_calls = sum(1 for detail in call_details_list if detail.get('is_effective', False))
                    scores = [detail['score'] for detail in call_details_list if detail.get('score') is not None]
                    
                    logger.info(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
                    logger.info(f"   æ€»é€šè¯æ•°: {total_calls}")
                    logger.info(f"   æœ‰æ•ˆé€šè¯æ•°: {effective_calls}")
                    logger.info(f"   æœ‰è¯„åˆ†é€šè¯æ•°: {len(scores)}")
                    
                    # è½¬æ¢æ•°æ®æ ¼å¼ï¼ˆJSONåºåˆ—åŒ–ï¼‰
                    for detail in call_details_list:
                        # ç§»é™¤é”™è¯¯çš„scoreå­—æ®µåºåˆ—åŒ–ï¼Œscoreæ˜¯æ•°å€¼å­—æ®µ
                        pass
                    
                    # æ‰¹é‡æ’å…¥é€šè¯è¯¦æƒ…
                    if call_details_list:
                        await db.batch_insert_call_details(
                            daily_record_id,
                            salesperson_id,
                            call_details_list
                        )
                        logger.info(f"âœ… æˆåŠŸæ’å…¥ {len(call_details_list)} æ¡é€šè¯è¯¦æƒ…")
                    
                    # è®¡ç®—å¹³å‡åˆ†
                    average_score = sum(scores) / len(scores) if scores else None
                    logger.info(f"ğŸ“Š å¹³å‡è¯„åˆ†: {average_score:.2f}" if average_score else "ğŸ“Š å¹³å‡è¯„åˆ†: æ— ")
                    
                    # ä»æ±‡æ€»åˆ†æä¸­æå–æ”¹è¿›å»ºè®®
                    from extract_utils import extract_all_summary_data
                    summary_data = extract_all_summary_data(summary_analysis)
                    improvement_suggestions = "\n".join(summary_data["improvement_measures"]) if summary_data["improvement_measures"] else None
                    
                    # å¦‚æœæ˜¯è¿½åŠ æ¨¡å¼ï¼Œéœ€è¦åˆå¹¶ç»Ÿè®¡æ•°æ®
                    if existing_record and current_upload_choice == "append":
                        logger.info(f"ğŸ”„ è¿½åŠ æ¨¡å¼ï¼šåˆå¹¶ç»Ÿè®¡æ•°æ®")
                        logger.info(f"   existing_record ID: {existing_record.get('id')}")
                        logger.info(f"   daily_record_id: {daily_record_id}")
                        
                        old_total = existing_record.get('total_calls', 0)
                        old_effective = existing_record.get('effective_calls', 0)
                        old_avg = existing_record.get('average_score')
                        
                        logger.info(f"   åŸæœ‰æ•°æ®: {old_total} é€šè¯, {old_effective} æœ‰æ•ˆ, å¹³å‡åˆ† {old_avg}")
                        logger.info(f"   æ–°å¢æ•°æ®: {len(call_details_list)} é€šè¯, {effective_calls} æœ‰æ•ˆ")
                        
                        # åˆå¹¶ç»Ÿè®¡æ•°æ®
                        total_calls += old_total
                        effective_calls += old_effective
                        
                        logger.info(f"   åˆå¹¶å: {total_calls} é€šè¯, {effective_calls} æœ‰æ•ˆ")
                        
                        # é‡æ–°è®¡ç®—å¹³å‡åˆ†
                        if old_avg and average_score:
                            old_avg_float = float(old_avg)
                            old_count = old_total
                            new_count = len(call_details_list)
                            if old_count + new_count > 0:
                                # è®¡ç®—åŠ æƒå¹³å‡åˆ†
                                weighted_avg = (old_avg_float * old_count + average_score * new_count) / (old_count + new_count)
                                logger.info(f"   åŸå¹³å‡åˆ†: {old_avg_float:.2f} (åŸºäº {old_count} ä¸ªé€šè¯)")
                                logger.info(f"   æ–°å¹³å‡åˆ†: {average_score:.2f} (åŸºäº {new_count} ä¸ªé€šè¯)")
                                logger.info(f"   åˆå¹¶åå¹³å‡åˆ†: {weighted_avg:.2f}")
                                average_score = weighted_avg
                    else:
                        logger.info(f"ğŸ“ éè¿½åŠ æ¨¡å¼æˆ–æ— ç°æœ‰è®°å½•:")
                        logger.info(f"   upload_choice: {current_upload_choice}")
                        logger.info(f"   existing_record: {'å­˜åœ¨' if existing_record else 'ä¸å­˜åœ¨'}")
                    
                    # ç¡®å®šæ˜¯å¦éœ€è¦åˆå¹¶åˆ†æç»“æœ
                    should_merge_analysis = (current_upload_choice == "append" and existing_record is not None)
                    logger.info(f"ğŸ“Š åˆ†æç»“æœåˆå¹¶è®¾ç½®: {should_merge_analysis}")
                    
                    # æ›´æ–°æ—¥å¸¸è®°å½•ç»Ÿè®¡ä¿¡æ¯
                    await db.update_daily_record_stats(
                        daily_record_id,
                        total_calls,
                        effective_calls,
                        average_score,
                        summary_analysis,
                        improvement_suggestions,
                        merge_analysis=should_merge_analysis
                    )
                    
                    # ğŸ¯ æ›´æ–°éŸ³é¢‘é€šè¯ä¸“é—¨çš„ç»Ÿè®¡å­—æ®µ
                    # æ ¹æ®æ“ä½œæ¨¡å¼å†³å®šæ˜¯å¦é‡ç½®éŸ³é¢‘æ•°æ®
                    reset_audio_data = (current_upload_choice == "overwrite" or 
                                      (not existing_record and current_upload_choice != "append"))
                    
                    # è®¡ç®—éŸ³é¢‘é€šè¯çš„å¢é‡
                    audio_calls_increment = len(call_details_list)
                    audio_effective_increment = sum(1 for detail in call_details_list if detail.get('is_effective', False))
                    
                    # æ›´æ–°éŸ³é¢‘é€šè¯ç»Ÿè®¡ï¼ˆåŒ…å«ä¿®å¤åçš„é€»è¾‘ï¼‰
                    await db.update_audio_call_statistics(
                        daily_record_id,
                        audio_calls_increment,
                        audio_effective_increment,
                        reset_audio_data=reset_audio_data
                    )
                    logger.info(f"âœ… å·²æ›´æ–°éŸ³é¢‘é€šè¯ç»Ÿè®¡å­—æ®µ: {audio_calls_increment} é€šè¯, {audio_effective_increment} æœ‰æ•ˆ")
                    
                    # æœ€ç»ˆéªŒè¯ï¼šæ£€æŸ¥ä¿å­˜åçš„çŠ¶æ€
                    async with db.acquire() as conn:
                        total_records_final = await conn.fetchval("SELECT COUNT(*) FROM daily_call_records")
                        total_details_final = await conn.fetchval("SELECT COUNT(*) FROM call_details")
                        logger.info(f"ğŸ‰ æœ€ç»ˆæ•°æ®åº“çŠ¶æ€:")
                        logger.info(f"   æ¯æ—¥è®°å½•æ€»æ•°: {total_records_final}")
                        logger.info(f"   é€šè¯è¯¦æƒ…æ€»æ•°: {total_details_final}")
                    
                    logger.info(f"âœ… æˆåŠŸä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“ï¼š{total_calls} ä¸ªé€šè¯ï¼Œ{effective_calls} ä¸ªæœ‰æ•ˆé€šè¯")
                    return True
                    
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    return False
                finally:
                    await db.close()
            return _async_save()
        
        return self._run_async(_save)
    
    def save_image_analysis_data(
        self,
        salesperson_id: int,
        processing_results: Dict[str, Any],
        upload_choice: Optional[str] = None
    ) -> bool:
        """
        åŒæ­¥ä¿å­˜å›¾ç‰‡è¯†åˆ«åˆ†ææ•°æ®åˆ°call_detailsè¡¨
        
        Args:
            salesperson_id: é”€å”®äººå‘˜ID
            processing_results: å›¾ç‰‡å¤„ç†ç»“æœï¼ŒåŒ…å«ï¼š
                - call_details_list: call_detailsæ ¼å¼çš„é€šè¯æ•°æ®åˆ—è¡¨
                - total_images_processed: å¤„ç†çš„å›¾ç‰‡æ•°é‡
                - total_calls_found: å‘ç°çš„æ€»é€šè¯æ•°
                - total_effective_calls: å‘ç°çš„æœ‰æ•ˆé€šè¯æ•°
                - processing_errors: å¤„ç†é”™è¯¯åˆ—è¡¨
            upload_choice: ä¸Šä¼ é€‰æ‹© ('overwrite', 'append', None)
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        def _save():
            async def _async_save():
                db = DatabaseManager(self.config)
                await db.initialize()
                try:
                    today = date.today()
                    
                    logger.info(f"ğŸ–¼ï¸ å¼€å§‹ä¿å­˜å›¾ç‰‡è¯†åˆ«æ•°æ®:")
                    logger.info(f"   é”€å”®äººå‘˜ID: {salesperson_id}")
                    logger.info(f"   ä¸Šä¼ æ—¥æœŸ: {today}")
                    logger.info(f"   å¤„ç†å›¾ç‰‡æ•°: {processing_results.get('total_images_processed', 0)}")
                    logger.info(f"   å‘ç°é€šè¯æ•°: {processing_results.get('total_calls_found', 0)}")
                    logger.info(f"   æœ‰æ•ˆé€šè¯æ•°: {processing_results.get('total_effective_calls', 0)}")
                    logger.info(f"   æ“ä½œæ¨¡å¼: {upload_choice}")
                    
                    # ä½¿ç”¨å±€éƒ¨å˜é‡æ¥é¿å…é‡æ–°èµ‹å€¼é—®é¢˜
                    current_upload_choice = upload_choice
                    
                    # è·å– call_details æ ¼å¼çš„æ•°æ®
                    call_details_list = processing_results.get("call_details_list", [])
                    
                    if not call_details_list:
                        logger.info("ğŸ“Š æ²¡æœ‰å‘ç°æœ‰æ•ˆçš„é€šè¯è®°å½•")
                        return True
                    
                    # ğŸ“Œ å‚è€ƒå½•éŸ³æ¿å—é€»è¾‘ï¼šå¤„ç†ç°æœ‰è®°å½•
                    existing_record = await db.get_daily_record(salesperson_id, today)
                    
                    # å¤„ç†è¦†ç›–æ¨¡å¼
                    if current_upload_choice == "overwrite" and existing_record:
                        logger.warning(f"âš ï¸ è¦†ç›–æ¨¡å¼ï¼šå‡†å¤‡åˆ é™¤é”€å”®äººå‘˜ {salesperson_id} åœ¨ {today} çš„ç°æœ‰è®°å½•")
                        logger.warning(f"   å³å°†åˆ é™¤çš„è®°å½•ID: {existing_record['id']}")
                        
                        # æŸ¥è¯¢å°†è¦åˆ é™¤çš„è¯¦æƒ…æ•°é‡
                        async with db.acquire() as conn:
                            details_to_delete = await conn.fetchval(
                                "SELECT COUNT(*) FROM call_details WHERE daily_record_id = $1",
                                existing_record['id']
                            )
                        logger.warning(f"   å°†åˆ é™¤ {details_to_delete} æ¡é€šè¯è¯¦æƒ…")
                        
                        # æ‰§è¡Œåˆ é™¤æ“ä½œ
                        await db.delete_daily_record_and_details(existing_record['id'])
                        existing_record = None  # é‡ç½®ç°æœ‰è®°å½•çŠ¶æ€
                    
                    # è·å–æˆ–åˆ›å»ºæ—¥å¸¸è®°å½•
                    if existing_record and current_upload_choice == "append":
                        daily_record_id = existing_record['id']
                        logger.info(f"ğŸ“ ä½¿ç”¨ç°æœ‰è®°å½• (è¿½åŠ æ¨¡å¼): ID {daily_record_id}")
                    elif existing_record and current_upload_choice is None:
                        # å¦‚æœå­˜åœ¨è®°å½•ä½†æ²¡æœ‰æŒ‡å®šæ“ä½œæ¨¡å¼ï¼Œé»˜è®¤ä½¿ç”¨è¿½åŠ æ¨¡å¼
                        daily_record_id = existing_record['id']
                        logger.info(f"ğŸ“ ä½¿ç”¨ç°æœ‰è®°å½• (é»˜è®¤è¿½åŠ æ¨¡å¼): ID {daily_record_id}")
                        current_upload_choice = "append"  # è®¾ç½®ä¸ºè¿½åŠ æ¨¡å¼
                    else:
                        # åˆ›å»ºæ–°è®°å½•ï¼ˆæ²¡æœ‰ç°æœ‰è®°å½•æˆ–è¦†ç›–æ¨¡å¼åˆ é™¤åï¼‰
                        daily_record_id = await db.create_daily_record(salesperson_id, today)
                        logger.info(f"ğŸ“ åˆ›å»ºæ–°è®°å½•: ID {daily_record_id}")
                    
                    # å‡†å¤‡ç»Ÿè®¡æ•°æ®
                    total_calls = len(call_details_list)
                    effective_calls = sum(1 for detail in call_details_list if detail.get('is_effective', False))
                    
                    logger.info(f"ğŸ“ˆ å›¾ç‰‡è¯†åˆ«ç»Ÿè®¡ä¿¡æ¯:")
                    logger.info(f"   æ€»é€šè¯æ•°: {total_calls}")
                    logger.info(f"   æœ‰æ•ˆé€šè¯æ•°: {effective_calls}")
                    logger.info(f"   å›¾ç‰‡è¯†åˆ«ä¸ä½¿ç”¨è¯„åˆ†å­—æ®µ")
                    
                    # æ‰¹é‡æ’å…¥é€šè¯è¯¦æƒ…åˆ°call_detailsè¡¨
                    if call_details_list:
                        await db.batch_insert_call_details(
                            daily_record_id,
                            salesperson_id,
                            call_details_list,
                            record_type='image'  # æ ‡è®°ä¸ºå›¾ç‰‡ç±»å‹
                        )
                        logger.info(f"âœ… æˆåŠŸæ’å…¥ {len(call_details_list)} æ¡å›¾ç‰‡é€šè¯è¯¦æƒ…")
                    
                    # å›¾ç‰‡è¯†åˆ«ä¸è®¡ç®—å¹³å‡åˆ†
                    average_score = None
                    logger.info(f"ğŸ“Š å›¾ç‰‡è¯†åˆ«æ¨¡å¼ï¼šä¸ä½¿ç”¨è¯„åˆ†å­—æ®µ")
                    
                    # ç”Ÿæˆç®€å•çš„æ±‡æ€»åˆ†æ
                    summary_analysis = generate_image_summary_analysis(call_details_list, processing_results)
                    improvement_suggestions = None  # å›¾ç‰‡è¯†åˆ«æš‚ä¸ç”Ÿæˆæ”¹è¿›å»ºè®®
                    
                    # å¦‚æœæ˜¯è¿½åŠ æ¨¡å¼ï¼Œéœ€è¦åˆå¹¶ç»Ÿè®¡æ•°æ®
                    if existing_record and current_upload_choice == "append":
                        logger.info(f"ğŸ”„ è¿½åŠ æ¨¡å¼ï¼šåˆå¹¶ç»Ÿè®¡æ•°æ®")
                        
                        old_total = existing_record.get('total_calls', 0)
                        old_effective = existing_record.get('effective_calls', 0)
                        old_avg = existing_record.get('average_score')
                        
                        logger.info(f"   åŸæœ‰æ•°æ®: {old_total} é€šè¯, {old_effective} æœ‰æ•ˆ, å¹³å‡åˆ† {old_avg}")
                        logger.info(f"   æ–°å¢æ•°æ®: {total_calls} é€šè¯, {effective_calls} æœ‰æ•ˆ")
                        
                        # åˆå¹¶ç»Ÿè®¡æ•°æ®
                        total_calls += old_total
                        effective_calls += old_effective
                        
                        logger.info(f"   åˆå¹¶å: {total_calls} é€šè¯, {effective_calls} æœ‰æ•ˆ")
                        
                        # å›¾ç‰‡è¯†åˆ«ä¸é‡æ–°è®¡ç®—å¹³å‡åˆ†ï¼ˆä¿æŒåŸæœ‰çš„å¹³å‡åˆ†ï¼‰
                        if old_avg:
                            logger.info(f"   ä¿æŒåŸæœ‰å¹³å‡åˆ†: {old_avg} (å›¾ç‰‡è¯†åˆ«ä¸å½±å“å¹³å‡åˆ†è®¡ç®—)")
                            average_score = old_avg
                        else:
                            logger.info(f"   å›¾ç‰‡è¯†åˆ«æ¨¡å¼ï¼šä¸è®¡ç®—å¹³å‡åˆ†")
                            average_score = None
                    
                    # ç¡®å®šæ˜¯å¦éœ€è¦åˆå¹¶åˆ†æç»“æœ
                    should_merge_analysis = (current_upload_choice == "append" and existing_record is not None)
                    logger.info(f"ğŸ“Š åˆ†æç»“æœåˆå¹¶è®¾ç½®: {should_merge_analysis}")
                    
                    # æ›´æ–°æ—¥å¸¸è®°å½•ç»Ÿè®¡ä¿¡æ¯
                    await db.update_daily_record_stats(
                        daily_record_id,
                        total_calls,
                        effective_calls,
                        average_score,
                        summary_analysis,
                        improvement_suggestions,
                        merge_analysis=should_merge_analysis
                    )
                    
                    # ğŸ¯ æ›´æ–°å›¾ç‰‡é€šè¯ä¸“é—¨çš„ç»Ÿè®¡å­—æ®µ
                    # æ ¹æ®æ“ä½œæ¨¡å¼å†³å®šæ˜¯å¦é‡ç½®å›¾ç‰‡æ•°æ®
                    reset_image_data = (current_upload_choice == "overwrite" or 
                                      (not existing_record and current_upload_choice != "append"))
                    
                    # è®¡ç®—å›¾ç‰‡é€šè¯çš„å¢é‡
                    image_calls_increment = len(call_details_list)
                    image_effective_increment = sum(1 for detail in call_details_list if detail.get('is_effective', False))
                    
                    # æ›´æ–°å›¾ç‰‡é€šè¯ç»Ÿè®¡ï¼ˆåŒ…å«ä¿®å¤åçš„é€»è¾‘ï¼‰
                    await db.update_image_call_statistics(
                        daily_record_id,
                        image_calls_increment,
                        image_effective_increment,
                        reset_image_data=reset_image_data
                    )
                    logger.info(f"âœ… å·²æ›´æ–°å›¾ç‰‡é€šè¯ç»Ÿè®¡å­—æ®µ: {image_calls_increment} é€šè¯, {image_effective_increment} æœ‰æ•ˆ")
                    
                    # å¤„ç†é”™è¯¯ä¿¡æ¯è®°å½•
                    errors = processing_results.get("processing_errors", [])
                    if errors:
                        logger.warning(f"âš ï¸ æœ‰ {len(errors)} å¼ å›¾ç‰‡å¤„ç†å¤±è´¥:")
                        for error in errors:
                            logger.warning(f"   - {error.get('filename', 'Unknown')}: {error.get('error', 'Unknown error')}")
                    
                    logger.info(f"âœ… å›¾ç‰‡è¯†åˆ«æ•°æ®ä¿å­˜å®Œæˆï¼š{total_calls} ä¸ªé€šè¯ï¼Œ{effective_calls} ä¸ªæœ‰æ•ˆé€šè¯")
                    return True
                    
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜å›¾ç‰‡è¯†åˆ«æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    return False
                finally:
                    await db.close()
            return _async_save()
        
        return self._run_async(_save)

def generate_image_summary_analysis(call_details_list: List[Dict[str, Any]], processing_results: Dict[str, Any]) -> str:
    """
    ç”Ÿæˆå›¾ç‰‡è¯†åˆ«çš„æ±‡æ€»åˆ†ææŠ¥å‘Š
    
    Args:
        call_details_list: é€šè¯è¯¦æƒ…åˆ—è¡¨
        processing_results: å¤„ç†ç»“æœ
        
    Returns:
        æ±‡æ€»åˆ†ææ–‡æœ¬
    """
    total_calls = len(call_details_list)
    effective_calls = sum(1 for detail in call_details_list if detail.get('is_effective', False))
    total_images = processing_results.get('total_images_processed', 0)
    
    # ç»Ÿè®¡å…¬å¸ä¿¡æ¯
    companies = set()
    contacts = set()
    
    for detail in call_details_list:
        if detail.get('company_name'):
            companies.add(detail['company_name'])
        if detail.get('contact_person'):
            contacts.add(detail['contact_person'])
    
    # å›¾ç‰‡è¯†åˆ«ä¸ä½¿ç”¨scoreå­—æ®µï¼Œä»analysis_textä¸­æå–æ—¶é•¿ä¿¡æ¯
    avg_duration = 0  # å›¾ç‰‡è¯†åˆ«æ¨¡å¼æš‚ä¸è®¡ç®—å¹³å‡æ—¶é•¿
    
    summary = f"""### ğŸ“¸ å›¾ç‰‡è¯†åˆ«æ±‡æ€»åˆ†ææŠ¥å‘Š

**åŸºæœ¬ç»Ÿè®¡ï¼š**
- å¤„ç†å›¾ç‰‡æ•°é‡ï¼š{total_images} å¼ 
- è¯†åˆ«é€šè¯è®°å½•ï¼š{total_calls} ä¸ª
- æœ‰æ•ˆé€šè¯ï¼ˆâ‰¥60ç§’ï¼‰ï¼š{effective_calls} ä¸ª
- æœ‰æ•ˆé€šè¯ç‡ï¼š{(effective_calls/total_calls*100):.1f}%" if total_calls > 0 else "æ— é€šè¯è®°å½•"

**ä¸šåŠ¡èŒƒå›´ï¼š**
- æ¶‰åŠå…¬å¸æ•°é‡ï¼š{len(companies)} å®¶
- è”ç³»äººæ•°é‡ï¼š{len(contacts)} äºº
- é€šè¯æ—¶é•¿ç»Ÿè®¡ï¼šè¯¦è§é€šè¯è¯¦æƒ…ä¸­çš„analysis_textå­—æ®µ

**è¯†åˆ«çš„å…¬å¸åˆ—è¡¨ï¼š**
{chr(10).join(f"- {company}" for company in sorted(companies)) if companies else "- æ— æ˜ç¡®å…¬å¸ä¿¡æ¯"}

**å¤‡æ³¨ï¼š** æœ¬åˆ†æåŸºäºå¾®ä¿¡é€šè¯æˆªå›¾è¯†åˆ«ï¼Œæ•°æ®å¯èƒ½å­˜åœ¨è¯†åˆ«è¯¯å·®ï¼Œå»ºè®®æ ¸å®é‡è¦ä¿¡æ¯ã€‚
"""
    
    return summary 